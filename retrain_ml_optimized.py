"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤.

–£–ª—É—á—à–µ–Ω–∏—è:
1. –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç (movement > 1%)
2. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (class_weight)
3. –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –¥–Ω–µ–π)
4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
"""
import warnings
import os

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
warnings.filterwarnings('ignore')

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from bot.config import load_settings
from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer


def main():
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", type=str, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    args = parser.parse_known_args()[0]
    
    print("=" * 80)
    print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = load_settings()
    
    # –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    symbols = [args.symbol] if args.symbol else ["SOLUSDT", "BTCUSDT", "ETHUSDT"]
    interval = "15"  # 15 –º–∏–Ω—É—Ç
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
        print("\n" + "=" * 80)
        print(f"üìä –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø {symbol}")
        print("=" * 80)
        
        # === –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (30 –¥–Ω–µ–π) ===
        print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}...")
        collector = DataCollector(settings.api)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        # 30 –¥–Ω–µ–π * 24 —á–∞—Å–∞ * 4 (15-–º–∏–Ω—É—Ç–∫–∏) = ~2880 —Å–≤–µ—á–µ–π
        df_raw = collector.collect_klines(
            symbol=symbol,
            interval=interval,
            start_date=None,
            end_date=None,
            limit=3000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 200 –¥–æ 3000 –¥–ª—è –±–æ–ª—å—à–µ–π –≥–ª—É–±–∏–Ω—ã
        )
        
        if df_raw.empty:
            print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue
        
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw)} —Å–≤–µ—á–µ–π (~{len(df_raw)/96:.1f} –¥–Ω–µ–π)")
        
        # === –®–∞–≥ 2: Feature Engineering ===
        print(f"\n[2/5] üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}...")
        feature_engineer = FeatureEngineer()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df_features = feature_engineer.create_technical_indicators(df_raw)
        feature_names = feature_engineer.get_feature_names()
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) ===
        print(f"\n[3/5] üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç)...")
        print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("   ‚Ä¢ Forward periods: 5 (75 –º–∏–Ω—É—Ç)")
        print("   ‚Ä¢ Threshold: 1.0% (–≤–º–µ—Å—Ç–æ 0.2%)")
        print("   ‚Ä¢ Risk/Reward: 1.5:1")
        print("   ‚Ä¢ Use ATR threshold: True")
        
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=5,  # 5 * 15m = 75 –º–∏–Ω—É—Ç (–≤–º–µ—Å—Ç–æ 4 = 60 –º–∏–Ω—É—Ç)
            threshold_pct=1.0,  # –£–≤–µ–ª–∏—á–µ–Ω —Å 0.2% –¥–æ 1.0% –¥–ª—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=1.5,  # –ú–µ–Ω—å—à–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        target_dist = df_with_target['target'].value_counts()
        print(f"\n‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–∑–¥–∞–Ω–∞")
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in target_dist.items():
            pct = count / len(df_with_target) * 100
            emoji = "üü¢" if label == 1 else ("üî¥" if label == -1 else "‚ö™")
            label_name = "LONG" if label == 1 else ("SHORT" if label == -1 else "HOLD")
            print(f"   {emoji} {label_name:5s}: {count:5d} ({pct:5.1f}%)")
        
        # === –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        print(f"\n[4/5] üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"   Features: {X.shape[0]} samples √ó {X.shape[1]} features")
        print(f"   Target: {y.shape[0]} labels")
        
        # === –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ ===
        print(f"\n[5/5] ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤...")
        trainer = ModelTrainer()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        # LONG –∏ SHORT –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å, HOLD - –º–µ–Ω—å—à–∏–π
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y)
        base_weights = compute_class_weight('balanced', classes=classes, y=y)
        
        # –£—Å–∏–ª–∏–≤–∞–µ–º –≤–µ—Å–∞ –¥–ª—è LONG/SHORT, –æ—Å–ª–∞–±–ª—è–µ–º –¥–ª—è HOLD
        class_weight_dict = {}
        for i, cls in enumerate(classes):
            if cls == 0:  # HOLD
                class_weight_dict[cls] = base_weights[i] * 0.3  # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å HOLD
            else:  # LONG or SHORT
                class_weight_dict[cls] = base_weights[i] * 2.0  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å LONG/SHORT
        
        print(f"\n   üìä –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
        for cls, weight in class_weight_dict.items():
            label_name = "LONG" if cls == 1 else ("SHORT" if cls == -1 else "HOLD")
            print(f"      {label_name}: {weight:.2f}")
        
        # –û–±—É—á–∞–µ–º Random Forest —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        rf_model, rf_metrics = trainer.train_random_forest_classifier(
            X, y,
            n_estimators=150,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 100 –¥–æ 150
            max_depth=12,      # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 10 –¥–æ 12
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            rf_model,
            trainer.scaler,
            feature_names,
            rf_metrics,
            f"rf_{symbol}_{interval}.pkl",
            symbol=symbol,
            interval=interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 12,
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 1.5,
            },
        )
        print(f"      ‚úÖ Accuracy: {rf_metrics['accuracy']:.4f}")
        print(f"      ‚úÖ CV Accuracy: {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º XGBoost —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   ‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost...")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º class_weight –≤ scale_pos_weight –¥–ª—è XGBoost
        # XGBoost –∏—Å–ø–æ–ª—å–∑—É–µ—Ç scale_pos_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        xgb_model, xgb_metrics = trainer.train_xgboost_classifier(
            X, y,
            n_estimators=150,    # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 100 –¥–æ 150
            max_depth=8,         # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 6 –¥–æ 8
            learning_rate=0.05,  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 0.1 –¥–æ 0.05 –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            xgb_model,
            trainer.scaler,
            feature_names,
            xgb_metrics,
            f"xgb_{symbol}_{interval}.pkl",
            symbol=symbol,
            interval=interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 8,
                "learning_rate": 0.05,
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 1.5,
            },
        )
        print(f"      ‚úÖ Accuracy: {xgb_metrics['accuracy']:.4f}")
        print(f"      ‚úÖ CV Accuracy: {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º Ensemble (RF + XGBoost)
        print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ Ensemble (RF + XGBoost)...")
        ensemble_model, ensemble_metrics = trainer.train_ensemble(
            X, y,
            rf_n_estimators=150,
            rf_max_depth=12,
            xgb_n_estimators=150,
            xgb_max_depth=8,
            xgb_learning_rate=0.05,
            ensemble_method="weighted_average",
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            ensemble_model,
            trainer.scaler,
            feature_names,
            ensemble_metrics,
            f"ensemble_{symbol}_{interval}.pkl",
            symbol=symbol,
            interval=interval,
            model_type="ensemble_weighted",
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "rf_n_estimators": 150,
                "rf_max_depth": 12,
                "xgb_n_estimators": 150,
                "xgb_max_depth": 8,
                "xgb_learning_rate": 0.05,
                "ensemble_method": "weighted_average",
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 1.5,
            },
        )
        print(f"      ‚úÖ Accuracy: {ensemble_metrics['accuracy']:.4f}")
        print(f"      ‚úÖ CV Accuracy: {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º TripleEnsemble (RF + XGBoost + LightGBM)
        from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
        if LIGHTGBM_AVAILABLE:
            print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ TripleEnsemble (RF + XGBoost + LightGBM)...")
            triple_ensemble_model, triple_ensemble_metrics = trainer.train_ensemble(
                X, y,
                rf_n_estimators=150,
                rf_max_depth=12,
                xgb_n_estimators=150,
                xgb_max_depth=8,
                xgb_learning_rate=0.05,
                lgb_n_estimators=150,
                lgb_max_depth=8,
                lgb_learning_rate=0.05,
                ensemble_method="triple",
                include_lightgbm=True,
                class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            trainer.save_model(
                triple_ensemble_model,
                trainer.scaler,
                feature_names,
                triple_ensemble_metrics,
                f"triple_ensemble_{symbol}_{interval}.pkl",
                symbol=symbol,
                interval=interval,
                model_type="triple_ensemble",
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "rf_n_estimators": 150,
                    "rf_max_depth": 12,
                    "xgb_n_estimators": 150,
                    "xgb_max_depth": 8,
                    "xgb_learning_rate": 0.05,
                    "lgb_n_estimators": 150,
                    "lgb_max_depth": 8,
                    "lgb_learning_rate": 0.05,
                    "ensemble_method": "triple",
                    "forward_periods": 5,
                    "threshold_pct": 1.0,
                    "min_risk_reward_ratio": 1.5,
                },
            )
            print(f"      ‚úÖ Accuracy: {triple_ensemble_metrics['accuracy']:.4f}")
            print(f"      ‚úÖ CV Accuracy: {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            print(f"      ‚úÖ Weights: RF={triple_ensemble_metrics['rf_weight']:.3f}, "
                  f"XGB={triple_ensemble_metrics['xgb_weight']:.3f}, "
                  f"LGB={triple_ensemble_metrics['lgb_weight']:.3f}")
        else:
            print(f"\n   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
            triple_ensemble_metrics = None
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print(f"\n" + "-" * 80)
        print(f"üìä –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø {symbol}")
        print("-" * 80)
        print(f"\nüå≤ Random Forest:")
        print(f"   Accuracy:     {rf_metrics['accuracy']:.4f}")
        print(f"   CV Accuracy:  {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        print(f"\n‚ö° XGBoost:")
        print(f"   Accuracy:     {xgb_metrics['accuracy']:.4f}")
        print(f"   CV Accuracy:  {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        print(f"\nüéØ Ensemble (RF+XGB):")
        print(f"   Accuracy:     {ensemble_metrics['accuracy']:.4f}")
        print(f"   Precision:    {ensemble_metrics['precision']:.4f}")
        print(f"   Recall:       {ensemble_metrics['recall']:.4f}")
        print(f"   F1-Score:     {ensemble_metrics['f1_score']:.4f}")
        print(f"   CV Accuracy:  {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        print(f"   CV F1-Score:  {ensemble_metrics['cv_f1_mean']:.4f}")
        
        if triple_ensemble_metrics:
            print(f"\nüéØ TripleEnsemble (RF+XGB+LGB):")
            print(f"   Accuracy:     {triple_ensemble_metrics['accuracy']:.4f}")
            print(f"   Precision:    {triple_ensemble_metrics['precision']:.4f}")
            print(f"   Recall:       {triple_ensemble_metrics['recall']:.4f}")
            print(f"   F1-Score:     {triple_ensemble_metrics['f1_score']:.4f}")
            print(f"   CV Accuracy:  {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            print(f"   CV F1-Score:  {triple_ensemble_metrics['cv_f1_mean']:.4f}")
            print(f"   Weights:      RF={triple_ensemble_metrics['rf_weight']:.3f}, "
                  f"XGB={triple_ensemble_metrics['xgb_weight']:.3f}, "
                  f"LGB={triple_ensemble_metrics['lgb_weight']:.3f}")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        models = [
            ("Random Forest", rf_metrics['cv_mean']),
            ("XGBoost", xgb_metrics['cv_mean']),
            ("Ensemble", ensemble_metrics['cv_mean']),
        ]
        if triple_ensemble_metrics:
            models.append(("TripleEnsemble", triple_ensemble_metrics['cv_mean']))
        models.sort(key=lambda x: x[1], reverse=True)
        best_model, best_score = models[0]
        
        print(f"\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {best_model}")
        print(f"   Cross-Validation Accuracy: {best_score:.4f}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    print("\n" + "=" * 80)
    print("üéâ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    print("\nüì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    print("   ‚Ä¢ ml_models/rf_*_15.pkl (Random Forest)")
    print("   ‚Ä¢ ml_models/xgb_*_15.pkl (XGBoost)")
    print("   ‚Ä¢ ml_models/ensemble_*_15.pkl (RF + XGBoost)")
    from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
    if LIGHTGBM_AVAILABLE:
        print("   ‚Ä¢ ml_models/triple_ensemble_*_15.pkl (RF + XGBoost + LightGBM)")
    print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
    print("      python test_ml_strategy.py --symbol SOLUSDT --days 7")
    print("   2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ, –∑–∞–¥–µ–ø–ª–æ–π—Ç–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä:")
    print("      scp ml_models/*.pkl user@server:/opt/crypto_bot/ml_models/")
    print("      ssh user@server 'sudo systemctl restart crypto-bot'")
    print("\nüí° –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: 50-100 —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ 7 –¥–Ω–µ–π (–≤–º–µ—Å—Ç–æ 19)")
    print("=" * 80)


if __name__ == "__main__":
    main()
