"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤.

–£–ª—É—á—à–µ–Ω–∏—è:
1. –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç (movement > 1%)
2. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (class_weight)
3. –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –¥–Ω–µ–π)
4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
"""
import warnings
import os
import sys

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows
if sys.platform == 'win32':
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å UTF-8 –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except:
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–≤–æ–¥ –±–µ–∑ —ç–º–æ–¥–∑–∏
        pass

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
warnings.filterwarnings('ignore')

from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from bot.config import load_settings
from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ (–∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è Windows)
def safe_print(*args, **kwargs):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π print, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–º–µ–Ω—è–µ—Ç —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏."""
    try:
        print(*args, **kwargs)
    except UnicodeEncodeError:
        # –ó–∞–º–µ–Ω—è–µ–º —ç–º–æ–¥–∑–∏ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏
        text = ' '.join(str(arg) for arg in args)
        text = text.replace('üöÄ', '[START]')
        text = text.replace('üìä', '[INFO]')
        text = text.replace('‚úÖ', '[OK]')
        text = text.replace('‚ùå', '[ERROR]')
        text = text.replace('‚è≥', '[WAIT]')
        text = text.replace('üî•', '[HOT]')
        text = text.replace('üì•', '[DOWNLOAD]')
        print(text, **kwargs)


def main():
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", type=str, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    args = parser.parse_known_args()[0]
    
    safe_print("=" * 80)
    safe_print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò")
    safe_print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    settings = load_settings()
    
    # –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    symbols = [args.symbol] if args.symbol else ["SOLUSDT", "BTCUSDT", "ETHUSDT"]
    base_interval = "15"  # 15 –º–∏–Ω—É—Ç (–±–∞–∑–æ–≤—ã–π –¢–§)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ MTF-—Ä–µ–∂–∏–º –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (—á–∏—Ç–∞–µ–º –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
    ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "1")
    ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")
    mode_suffix = "mtf" if ml_mtf_enabled else "15m"
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
        print("\n" + "=" * 80)
        safe_print(f"üìä –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø {symbol}")
        print("=" * 80)
        
        # === –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (30 –¥–Ω–µ–π) ===
        if ml_mtf_enabled:
            print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (15m, 1h, 4h) –¥–ª—è {symbol}...")
        else:
            print(f"\n[1/5] üì• –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (15m only) –¥–ª—è {symbol}...")
        collector = DataCollector(settings.api)
        
        if ml_mtf_enabled:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            mtf_data = collector.collect_multiple_timeframes(
                symbol=symbol,
                intervals=[base_interval, "60", "240"],  # 15m, 1h, 4h
                start_date=None,
                end_date=None,
            )
            
            df_raw_15m = mtf_data.get(base_interval)
            df_raw_1h = mtf_data.get("60")
            df_raw_4h = mtf_data.get("240")
            
            if df_raw_15m is None or df_raw_15m.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (15m) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_15m)} —Å–≤–µ—á–µ–π 15m (~{len(df_raw_15m)/96:.1f} –¥–Ω–µ–π)")
        else:
            # –°—Ç–∞—Ä—ã–π —Ä–µ–∂–∏–º: —Å–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ 15m –¥–∞–Ω–Ω—ã–µ
            df_raw_15m = collector.collect_klines(
                symbol=symbol,
                interval=base_interval,
                start_date=None,
                end_date=None,
                limit=3000,
            )
            if df_raw_15m.empty:
                safe_print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (15m) –¥–ª—è {symbol}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue
            safe_print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw_15m)} —Å–≤–µ—á–µ–π 15m (~{len(df_raw_15m)/96:.1f} –¥–Ω–µ–π)")
        
        # === –®–∞–≥ 2: Feature Engineering ===
        print(f"\n[2/5] üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}...")
        feature_engineer = FeatureEngineer()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –±–∞–∑–æ–≤–æ–º –¢–§ (15m)
        df_features = feature_engineer.create_technical_indicators(df_raw_15m)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º—É–ª—å—Ç–∏‚Äë—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (1h, 4h), –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å –∏ MTF –≤–∫–ª—é—á–µ–Ω
        if ml_mtf_enabled:
            higher_timeframes = {}
            df_raw_1h = mtf_data.get("60")
            df_raw_4h = mtf_data.get("240")
            if df_raw_1h is not None and not df_raw_1h.empty:
                higher_timeframes["60"] = df_raw_1h
            if df_raw_4h is not None and not df_raw_4h.empty:
                higher_timeframes["240"] = df_raw_4h
            
            if higher_timeframes:
                df_features = feature_engineer.add_mtf_features(df_features, higher_timeframes)
                safe_print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã MTF‚Äë–ø—Ä–∏–∑–Ω–∞–∫–∏ (1h/4h). –í—Å–µ–≥–æ —Ñ–∏—á: {len(feature_engineer.get_feature_names())}")
            else:
                safe_print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è 1h/4h ‚Äî –æ–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ 15m –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.")
        
        feature_names = feature_engineer.get_feature_names()
        safe_print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) ===
        print(f"\n[3/5] üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–∞—Ä–≥–µ—Ç)...")
        print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("   ‚Ä¢ Forward periods: 5 (75 –º–∏–Ω—É—Ç)")
        print("   ‚Ä¢ Threshold: 1.0% (–≤–º–µ—Å—Ç–æ 0.2%)")
        print("   ‚Ä¢ Risk/Reward: 1.5:1")
        print("   ‚Ä¢ Use ATR threshold: True")
        
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=5,  # 5 * 15m = 75 –º–∏–Ω—É—Ç (–≤–º–µ—Å—Ç–æ 4 = 60 –º–∏–Ω—É—Ç)
            threshold_pct=1.0,  # –£–≤–µ–ª–∏—á–µ–Ω —Å 0.2% –¥–æ 1.0% –¥–ª—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º TP=25%, SL=10%)
            max_hold_periods=48,  # –ú–∞–∫—Å–∏–º—É–º 48 * 15m = 12 —á–∞—Å–æ–≤ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (—Å–º—è–≥—á–µ–Ω–æ: –±—ã–ª–æ 32)
            min_profit_pct=1.0,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å 1.0% –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞–∫ LONG/SHORT (—Å–º—è–≥—á–µ–Ω–æ: –±—ã–ª–æ 1.5%)
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        target_dist = df_with_target['target'].value_counts()
        safe_print(f"\n‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–∑–¥–∞–Ω–∞")
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in target_dist.items():
            pct = count / len(df_with_target) * 100
            emoji = "üü¢" if label == 1 else ("üî¥" if label == -1 else "‚ö™")
            label_name = "LONG" if label == 1 else ("SHORT" if label == -1 else "HOLD")
            print(f"   {emoji} {label_name:5s}: {count:5d} ({pct:5.1f}%)")
        
        # === –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        print(f"\n[4/5] üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        safe_print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"   Features: {X.shape[0]} samples √ó {X.shape[1]} features")
        print(f"   Target: {y.shape[0]} labels")
        
        # === –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ ===
        print(f"\n[5/5] ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤...")
        trainer = ModelTrainer()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        # LONG –∏ SHORT –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å, HOLD - –º–µ–Ω—å—à–∏–π
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y)
        base_weights = compute_class_weight('balanced', classes=classes, y=y)
        
        # –£–°–ò–õ–ï–ù–ù–´–ï –≤–µ—Å–∞ –¥–ª—è LONG/SHORT, –ú–ò–ù–ò–ú–ò–ó–ò–†–£–ï–ú HOLD (—Ñ–æ–∫—É—Å –Ω–∞ –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö)
        class_weight_dict = {}
        for i, cls in enumerate(classes):
            if cls == 0:  # HOLD
                class_weight_dict[cls] = base_weights[i] * 0.1  # –°–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å HOLD (–±—ã–ª–æ 0.3)
            else:  # LONG or SHORT
                class_weight_dict[cls] = base_weights[i] * 3.0  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å LONG/SHORT (–±—ã–ª–æ 2.0)
        
        safe_print(f"\n   üìä –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
        for cls, weight in class_weight_dict.items():
            label_name = "LONG" if cls == 1 else ("SHORT" if cls == -1 else "HOLD")
            print(f"      {label_name}: {weight:.2f}")
        
        # –û–±—É—á–∞–µ–º Random Forest —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        rf_model, rf_metrics = trainer.train_random_forest_classifier(
            X, y,
            n_estimators=150,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 100 –¥–æ 150
            max_depth=12,      # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 10 –¥–æ 12
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            rf_model,
            trainer.scaler,
            feature_names,
            rf_metrics,
            f"rf_{symbol}_{base_interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=base_interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 12,
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1
            },
        )
        safe_print(f"      ‚úÖ Accuracy: {rf_metrics['accuracy']:.4f}")
        safe_print(f"      ‚úÖ CV Accuracy: {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º XGBoost —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   ‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost...")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º class_weight –≤ scale_pos_weight –¥–ª—è XGBoost
        # XGBoost –∏—Å–ø–æ–ª—å–∑—É–µ—Ç scale_pos_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        xgb_model, xgb_metrics = trainer.train_xgboost_classifier(
            X, y,
            n_estimators=150,    # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 100 –¥–æ 150
            max_depth=8,         # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 6 –¥–æ 8
            learning_rate=0.05,  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 0.1 –¥–æ 0.05 –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            xgb_model,
            trainer.scaler,
            feature_names,
            xgb_metrics,
            f"xgb_{symbol}_{base_interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=base_interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 8,
                "learning_rate": 0.05,
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1
            },
        )
        safe_print(f"      ‚úÖ Accuracy: {xgb_metrics['accuracy']:.4f}")
        safe_print(f"      ‚úÖ CV Accuracy: {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º Ensemble (RF + XGBoost)
        print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ Ensemble (RF + XGBoost)...")
        ensemble_model, ensemble_metrics = trainer.train_ensemble(
            X, y,
            rf_n_estimators=150,
            rf_max_depth=12,
            xgb_n_estimators=150,
            xgb_max_depth=8,
            xgb_learning_rate=0.05,
            ensemble_method="weighted_average",
            class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            ensemble_model,
            trainer.scaler,
            feature_names,
            ensemble_metrics,
            f"ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=base_interval,
            model_type="ensemble_weighted",
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "rf_n_estimators": 150,
                "rf_max_depth": 12,
                "xgb_n_estimators": 150,
                "xgb_max_depth": 8,
                "xgb_learning_rate": 0.05,
                "ensemble_method": "weighted_average",
                "forward_periods": 5,
                "threshold_pct": 1.0,
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1
            },
        )
        safe_print(f"      ‚úÖ Accuracy: {ensemble_metrics['accuracy']:.4f}")
        safe_print(f"      ‚úÖ CV Accuracy: {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º TripleEnsemble (RF + XGBoost + LightGBM)
        from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
        if LIGHTGBM_AVAILABLE:
            print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ TripleEnsemble (RF + XGBoost + LightGBM)...")
            triple_ensemble_model, triple_ensemble_metrics = trainer.train_ensemble(
                X, y,
                rf_n_estimators=150,
                rf_max_depth=12,
                xgb_n_estimators=150,
                xgb_max_depth=8,
                xgb_learning_rate=0.05,
                lgb_n_estimators=150,
                lgb_max_depth=8,
                lgb_learning_rate=0.05,
                ensemble_method="triple",
                include_lightgbm=True,
                class_weight=class_weight_dict,  # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤!
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            trainer.save_model(
                triple_ensemble_model,
                trainer.scaler,
                feature_names,
                triple_ensemble_metrics,
                f"triple_ensemble_{symbol}_{base_interval}_{mode_suffix}.pkl",
                symbol=symbol,
                interval=base_interval,
                model_type="triple_ensemble",
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "rf_n_estimators": 150,
                    "rf_max_depth": 12,
                    "xgb_n_estimators": 150,
                    "xgb_max_depth": 8,
                    "xgb_learning_rate": 0.05,
                    "lgb_n_estimators": 150,
                    "lgb_max_depth": 8,
                    "lgb_learning_rate": 0.05,
                    "ensemble_method": "triple",
                    "forward_periods": 5,
                    "threshold_pct": 1.0,
                    "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1
                },
            )
            safe_print(f"      ‚úÖ Accuracy: {triple_ensemble_metrics['accuracy']:.4f}")
            safe_print(f"      ‚úÖ CV Accuracy: {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            safe_print(f"      ‚úÖ Weights: RF={triple_ensemble_metrics['rf_weight']:.3f}, "
                  f"XGB={triple_ensemble_metrics['xgb_weight']:.3f}, "
                  f"LGB={triple_ensemble_metrics['lgb_weight']:.3f}")
        else:
            print(f"\n   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
            triple_ensemble_metrics = None
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print(f"\n" + "-" * 80)
        safe_print(f"üìä –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –î–õ–Ø {symbol}")
        print("-" * 80)
        print(f"\nüå≤ Random Forest:")
        print(f"   Accuracy:     {rf_metrics['accuracy']:.4f}")
        print(f"   CV Accuracy:  {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        print(f"\n‚ö° XGBoost:")
        print(f"   Accuracy:     {xgb_metrics['accuracy']:.4f}")
        print(f"   CV Accuracy:  {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        print(f"\nüéØ Ensemble (RF+XGB):")
        print(f"   Accuracy:     {ensemble_metrics['accuracy']:.4f}")
        print(f"   Precision:    {ensemble_metrics['precision']:.4f}")
        print(f"   Recall:       {ensemble_metrics['recall']:.4f}")
        print(f"   F1-Score:     {ensemble_metrics['f1_score']:.4f}")
        print(f"   CV Accuracy:  {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        print(f"   CV F1-Score:  {ensemble_metrics['cv_f1_mean']:.4f}")
        
        if triple_ensemble_metrics:
            print(f"\nüéØ TripleEnsemble (RF+XGB+LGB):")
            print(f"   Accuracy:     {triple_ensemble_metrics['accuracy']:.4f}")
            print(f"   Precision:    {triple_ensemble_metrics['precision']:.4f}")
            print(f"   Recall:       {triple_ensemble_metrics['recall']:.4f}")
            print(f"   F1-Score:     {triple_ensemble_metrics['f1_score']:.4f}")
            print(f"   CV Accuracy:  {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            print(f"   CV F1-Score:  {triple_ensemble_metrics['cv_f1_mean']:.4f}")
            print(f"   Weights:      RF={triple_ensemble_metrics['rf_weight']:.3f}, "
                  f"XGB={triple_ensemble_metrics['xgb_weight']:.3f}, "
                  f"LGB={triple_ensemble_metrics['lgb_weight']:.3f}")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        models = [
            ("Random Forest", rf_metrics['cv_mean']),
            ("XGBoost", xgb_metrics['cv_mean']),
            ("Ensemble", ensemble_metrics['cv_mean']),
        ]
        if triple_ensemble_metrics:
            models.append(("TripleEnsemble", triple_ensemble_metrics['cv_mean']))
        models.sort(key=lambda x: x[1], reverse=True)
        best_model, best_score = models[0]
        
        safe_print(f"\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {best_model}")
        safe_print(f"   Cross-Validation Accuracy: {best_score:.4f}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    print("\n" + "=" * 80)
    print("üéâ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    print("\nüì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    print("   ‚Ä¢ ml_models/rf_*_15.pkl (Random Forest)")
    print("   ‚Ä¢ ml_models/xgb_*_15.pkl (XGBoost)")
    print("   ‚Ä¢ ml_models/ensemble_*_15.pkl (RF + XGBoost)")
    from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
    if LIGHTGBM_AVAILABLE:
        print("   ‚Ä¢ ml_models/triple_ensemble_*_15.pkl (RF + XGBoost + LightGBM)")
    safe_print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
    print("      python test_ml_strategy.py --symbol SOLUSDT --days 7")
    print("   2. –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ, –∑–∞–¥–µ–ø–ª–æ–π—Ç–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä:")
    print("      scp ml_models/*.pkl user@server:/opt/crypto_bot/ml_models/")
    print("      ssh user@server 'sudo systemctl restart crypto-bot'")
    print("\nüí° –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: 50-100 —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ 7 –¥–Ω–µ–π (–≤–º–µ—Å—Ç–æ 19)")
    print("=" * 80)


if __name__ == "__main__":
    main()
