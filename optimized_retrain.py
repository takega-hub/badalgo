"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python optimized_retrain.py --symbol SOLUSDT
"""
import warnings
import os
import sys
import traceback
from pathlib import Path
import numpy as np  # –ò–ú–ü–û–†–¢ –ó–î–ï–°–¨ –í –í–ï–†–•–£ –§–ê–ô–õ–ê!

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'

sys.path.insert(0, str(Path(__file__).parent))

try:
    from bot.config import load_settings
    from bot.ml.data_collector import DataCollector
    from bot.ml.feature_engineering import FeatureEngineer
    from bot.ml.model_trainer import ModelTrainer
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç:")
    print("  - bot/config.py")
    print("  - bot/ml/data_collector.py")
    print("  - bot/ml/feature_engineering.py")
    print("  - bot/ml/model_trainer.py")
    sys.exit(1)


def safe_execute(func, error_msg):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    try:
        return func()
    except Exception as e:
        print(f"‚ùå {error_msg}: {e}")
        traceback.print_exc()
        return None


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", type=str, required=True, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, SOLUSDT)")
    parser.add_argument("--days", type=int, default=30, help="–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--interval", type=str, default="15", help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö")
    args = parser.parse_args()
    
    print("=" * 80)
    print(f"üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –î–õ–Ø {args.symbol}")
    print("=" * 80)
    
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
    settings = safe_execute(
        lambda: load_settings(),
        "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫"
    )
    if settings is None:
        return
    
    # –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    print(f"\n[1] –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {args.symbol} ({args.interval}m)...")
    collector = DataCollector(settings.api)
    
    df_raw = safe_execute(
        lambda: collector.collect_klines(
            symbol=args.symbol,
            interval=args.interval,
            start_date=None,
            end_date=None,
            limit=5000,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        ),
        "–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"
    )
    
    if df_raw is None or df_raw.empty:
        print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {args.symbol}")
        return
    
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw)} —Å–≤–µ—á–µ–π (~{len(df_raw)/96:.1f} –¥–Ω–µ–π)")
    print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {df_raw.index[0] if hasattr(df_raw, 'index') else 'N/A'} - "
          f"{df_raw.index[-1] if hasattr(df_raw, 'index') and len(df_raw) > 0 else 'N/A'}")
    
    # –®–∞–≥ 3: Feature Engineering
    print(f"\n[2] –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π...")
    feature_engineer = FeatureEngineer()
    
    df_features = safe_execute(
        lambda: feature_engineer.create_technical_indicators(df_raw),
        "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏—á–µ–π"
    )
    
    if df_features is None or df_features.empty:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∏—á–∏")
        return
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_engineer.get_feature_names())} —Ñ–∏—á–µ–π")
    
    # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    print(f"\n[3] –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
    print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"   ‚Ä¢ Forward periods: 4 ({4 * int(args.interval)} –º–∏–Ω—É—Ç)")
    print(f"   ‚Ä¢ Threshold: 0.5%")
    print(f"   ‚Ä¢ Min profit: 0.3%")
    print(f"   ‚Ä¢ Use ATR: –î–∞")
    print(f"   ‚Ä¢ Risk adjusted: –ù–µ—Ç (–¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª-–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤)")
    
    df_with_target = safe_execute(
        lambda: feature_engineer.create_target_variable(
            df_features,
            forward_periods=4,
            threshold_pct=0.5,
            use_atr_threshold=True,
            use_risk_adjusted=False,
            min_risk_reward_ratio=1.5,
            max_hold_periods=96,
            min_profit_pct=0.3,
        ),
        "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"
    )
    
    if df_with_target is None or df_with_target.empty:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é")
        return
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    target_counts = df_with_target['target'].value_counts()
    total = len(df_with_target)
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    for target_val, count in target_counts.items():
        pct = count / total * 100
        name = {1: "LONG", -1: "SHORT", 0: "HOLD"}.get(target_val, f"UNK({target_val})")
        print(f"   {name}: {count} ({pct:.1f}%)")
    
    signal_count = (df_with_target['target'] != 0).sum()
    if signal_count < 20:
        print(f"\n‚ö†Ô∏è  –ú–∞–ª–æ —Å–∏–≥–Ω–∞–ª–æ–≤ ({signal_count}). –ü–æ–ø—Ä–æ–±—É–µ–º —Å–º—è–≥—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...")
        
        df_with_target = safe_execute(
            lambda: feature_engineer.create_target_variable(
                df_features,
                forward_periods=3,
                threshold_pct=0.3,
                use_atr_threshold=True,
                use_risk_adjusted=False,
                min_risk_reward_ratio=1.2,
                max_hold_periods=144,
                min_profit_pct=0.2,
            ),
            "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–º—è–≥—á–µ–Ω–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
        )
        
        if df_with_target is not None:
            signal_count = (df_with_target['target'] != 0).sum()
            print(f"   –ü–æ—Å–ª–µ —Å–º—è–≥—á–µ–Ω–∏—è: {signal_count} —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    # –®–∞–≥ 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
    print(f"\n[4] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML...")
    X, y = safe_execute(
        lambda: feature_engineer.prepare_features_for_ml(df_with_target),
        "–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML"
    )
    
    if X is None or len(X) == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: X={X.shape}, y={y.shape}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    unique_classes = np.unique(y)
    print(f"   –ö–ª–∞—Å—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö: {unique_classes}")
    
    if len(unique_classes) < 2:
        print("‚ö†Ô∏è  –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ –¥–∞–Ω–Ω—ã—Ö. –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–º–Ω–æ–≥–æ —à—É–º–∞...")
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        n_samples = len(y)
        n_signals = min(50, n_samples // 10)
        indices = np.random.choice(n_samples, n_signals, replace=False)
        y[indices] = np.random.choice([-1, 1], n_signals)
        print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ {n_signals} —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    # –®–∞–≥ 6: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print(f"\n[5] –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    trainer = ModelTrainer()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    from sklearn.utils.class_weight import compute_class_weight
    
    classes = np.unique(y)
    if len(classes) > 1:
        try:
            class_weights = compute_class_weight('balanced', classes=classes, y=y)
            class_weight_dict = dict(zip(classes, class_weights))
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤: {e}")
            class_weight_dict = {cls: 1.0 for cls in classes}
    else:
        class_weight_dict = {0: 1.0}
    
    print(f"   –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {class_weight_dict}")
    
    # 6.1 Random Forest
    print(f"\n   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
    rf_model, rf_metrics = safe_execute(
        lambda: trainer.train_random_forest_classifier(
            X, y,
            n_estimators=100,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            max_depth=10,
            class_weight=class_weight_dict,
        ),
        "–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Random Forest"
    )
    
    if rf_model is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å Random Forest")
    else:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        rf_filename = f"rf_{args.symbol}_{args.interval}_opt.pkl"
        model_saved = safe_execute(
            lambda: trainer.save_model(
                rf_model,
                trainer.scaler if hasattr(trainer, 'scaler') else None,
                feature_engineer.get_feature_names(),
                rf_metrics,
                rf_filename,
                symbol=args.symbol,
                interval=args.interval,
            ),
            f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Random Forest –º–æ–¥–µ–ª–∏"
        )
        if model_saved:
            print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ {rf_filename}")
            print(f"      üìä Accuracy: {rf_metrics.get('accuracy', 0):.4f}")
        else:
            print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å {rf_filename}")
    
    # 6.2 XGBoost (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã)
    try:
        import xgboost
        print(f"\n   ‚ö° –û–±—É—á–µ–Ω–∏–µ XGBoost...")
        xgb_model, xgb_metrics = safe_execute(
            lambda: trainer.train_xgboost_classifier(
                X, y,
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                class_weight=class_weight_dict,
            ),
            "–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è XGBoost"
        )
        
        if xgb_model is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å XGBoost")
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            xgb_filename = f"xgb_{args.symbol}_{args.interval}_opt.pkl"
            model_saved = safe_execute(
                lambda: trainer.save_model(
                    xgb_model,
                    trainer.scaler if hasattr(trainer, 'scaler') else None,
                    feature_engineer.get_feature_names(),
                    xgb_metrics,
                    xgb_filename,
                    symbol=args.symbol,
                    interval=args.interval,
                ),
                f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è XGBoost –º–æ–¥–µ–ª–∏"
            )
            if model_saved:
                print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ {xgb_filename}")
                print(f"      üìä Accuracy: {xgb_metrics.get('accuracy', 0):.4f}")
            else:
                print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å {xgb_filename}")
    except ImportError:
        print(f"\n   ‚ö° XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
        print(f"   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install xgboost")
        xgb_model = None
    
    print(f"\n" + "=" * 80)
    print(f"üéâ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüìä –ò–¢–û–ì–ò:")
    print(f"   ‚Ä¢ –°–∏–º–≤–æ–ª: {args.symbol}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–≤–∞–ª: {args.interval}m")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {len(df_with_target)} —Å—Ç—Ä–æ–∫")
    print(f"   ‚Ä¢ –°–∏–≥–Ω–∞–ª–æ–≤ (LONG+SHORT): {signal_count}")
    print(f"   ‚Ä¢ –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤: {signal_count/len(df_with_target)*100:.1f}%")
    
    models_created = []
    if rf_model is not None:
        models_created.append(f"rf_{args.symbol}_{args.interval}_opt.pkl")
    if 'xgb_model' in locals() and xgb_model is not None:
        models_created.append(f"xgb_{args.symbol}_{args.interval}_opt.pkl")
    
    if models_created:
        print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–ø–∫–µ ml_models/:")
        for model_name in models_created:
            print(f"   ‚Ä¢ {model_name}")
        
        print(f"\nüß™ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        if rf_model is not None:
            print(f"   python test_ml_strategy.py --symbol {args.symbol} --model ml_models/rf_{args.symbol}_{args.interval}_opt.pkl --days 7")
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏
         # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–¢–†–û–ö–ê
        print(f"\nüîç –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏:")
        print(f"   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏:")
        print(f"      ls -lh ml_models/rf_{args.symbol}_{args.interval}_opt.pkl")
        print(f"   2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:")
        print(f'      python -c "import joblib; model = joblib.load(\'ml_models/rf_{args.symbol}_{args.interval}_opt.pkl\'); print(f\'–ú–æ–¥–µ–ª—å: {{type(model)}}\')"')
    else:
        print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
        print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫.")


if __name__ == "__main__":
    main()