"""
–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏.
–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –Ω–∞ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤.
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from bot.ml.data_collector import DataCollector
from bot.ml.feature_engineering import FeatureEngineer
from bot.ml.model_trainer import ModelTrainer
from bot.config import load_settings
import warnings
warnings.filterwarnings('ignore')

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", type=str, help="–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    args = parser.parse_known_args()[0]
    
    print("=" * 80)
    print("üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–°–ò–í–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï ML")
    print("=" * 80)
    
    settings = load_settings()
    # –ï—Å–ª–∏ —Å–∏–º–≤–æ–ª –ø–µ—Ä–µ–¥–∞–Ω —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ –≤—Å–µ —Ç—Ä–∏
    symbols = [args.symbol] if args.symbol else ["SOLUSDT", "BTCUSDT", "ETHUSDT"]
    interval = "15"
    
    for symbol in symbols:
        print(f"\n{'='*80}")
        print(f"üéØ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï: {symbol}")
        print(f"{'='*80}")
        
        # === –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ===
        print(f"\n[1/5] üìä –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        collector = DataCollector(settings.api)
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ 6 –º–µ—Å—è—Ü–µ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é start_date = 180 –¥–Ω–µ–π –Ω–∞–∑–∞–¥)
        df_raw = collector.collect_klines(
            symbol=symbol,
            interval=interval,
            limit=200,
            save_to_file=False,  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        )
        
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df_raw)} —Å–≤–µ—á–µ–π")
        
        # === –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
        print(f"\n[2/5] üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        feature_engineer = FeatureEngineer()
        df_features = feature_engineer.create_technical_indicators(df_raw)
        feature_names = feature_engineer.get_feature_names()
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # === –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –ê–ì–†–ï–°–°–ò–í–ù–û–ì–û —Ç–∞—Ä–≥–µ—Ç–∞ ===
        print(f"\n[3/5] üî• –°–æ–∑–¥–∞–Ω–∏–µ –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
        print("   üî• –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ):")
        print("   ‚Ä¢ Forward periods: 3 (45 –º–∏–Ω—É—Ç, –±—ã–ª–æ 75)")
        print("   ‚Ä¢ Threshold: 0.6% (–±—ã–ª–æ 1.0%)")
        print("   ‚Ä¢ Risk/Reward: 1.2:1 (–±—ã–ª–æ 1.5:1)")
        print("   ‚Ä¢ –¶–µ–ª—å: –õ–æ–≤–∏—Ç—å –¥–∞–∂–µ —Å–ª–∞–±—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è!")
        
        df_with_target = feature_engineer.create_target_variable(
            df_features,
            forward_periods=3,  # 3 * 15m = 45 –º–∏–Ω—É—Ç (–∫–æ—Ä–æ—á–µ!)
            threshold_pct=0.6,  # 0.6% (–º—è–≥—á–µ!)
            use_atr_threshold=True,
            use_risk_adjusted=True,
            min_risk_reward_ratio=2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º TP=25%, SL=10%)
            max_hold_periods=48,  # –ú–∞–∫—Å–∏–º—É–º 48 * 15m = 12 —á–∞—Å–æ–≤ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (—Å–º—è–≥—á–µ–Ω–æ: –±—ã–ª–æ 32)
            min_profit_pct=1.0,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å 1.0% –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞–∫ LONG/SHORT (—Å–º—è–≥—á–µ–Ω–æ: –±—ã–ª–æ 1.5%)
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        target_dist = df_with_target['target'].value_counts()
        print(f"\n‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å–æ–∑–¥–∞–Ω–∞")
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in target_dist.items():
            pct = count / len(df_with_target) * 100
            emoji = "üü¢" if label == 1 else ("üî¥" if label == -1 else "‚ö™")
            label_name = "LONG" if label == 1 else ("SHORT" if label == -1 else "HOLD")
            print(f"   {emoji} {label_name:5s}: {count:5d} ({pct:5.1f}%)")
        
        # === –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
        print(f"\n[4/5] üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        X, y = feature_engineer.prepare_features_for_ml(df_with_target)
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"   Features: {X.shape[0]} samples √ó {X.shape[1]} features")
        print(f"   Target: {y.shape[0]} labels")
        
        # === –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ —Å –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û–ô –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π ===
        print(f"\n[5/5] üî• –û–±—É—á–µ–Ω–∏–µ —Å –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û–ô –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤...")
        trainer = ModelTrainer()
        
        # –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ï –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y)
        base_weights = compute_class_weight('balanced', classes=classes, y=y)
        
        # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û —É—Å–∏–ª–∏–≤–∞–µ–º LONG/SHORT, –ú–ò–ù–ò–ú–ò–ó–ò–†–£–ï–ú HOLD
        class_weight_dict = {}
        for i, cls in enumerate(classes):
            if cls == 0:  # HOLD
                class_weight_dict[cls] = base_weights[i] * 0.05  # üî• –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π –≤–µ—Å HOLD
            else:  # LONG or SHORT
                class_weight_dict[cls] = base_weights[i] * 4.0  # üî• –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –≤–µ—Å (—É–≤–µ–ª–∏—á–µ–Ω–æ —Å 3.0 –¥–æ 4.0)
        
        print(f"\n   üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ï –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
        for cls, weight in class_weight_dict.items():
            label_name = "LONG" if cls == 1 else ("SHORT" if cls == -1 else "HOLD")
            multiplier = weight / base_weights[list(classes).index(cls)]
            print(f"      {label_name}: {weight:.3f} (x{multiplier:.1f})")
        
        # –û–±—É—á–∞–µ–º Random Forest —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   üî• –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        rf_model, rf_metrics = trainer.train_random_forest_classifier(
            X, y,
            n_estimators=150,
            max_depth=12,
            class_weight=class_weight_dict,  # üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞!
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å —Ä–µ–∂–∏–º–∞ (MTF –∏–ª–∏ 15m-only) –ø–æ —Ñ–ª–∞–≥—É –æ–∫—Ä—É–∂–µ–Ω–∏—è
        ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "1")
        ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")
        mode_suffix = "mtf" if ml_mtf_enabled else "15m"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            rf_model,
            trainer.scaler,
            feature_names,
            rf_metrics,
            f"rf_{symbol}_{interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 12,
                "forward_periods": 3,  # üî• –ö–æ—Ä–æ—á–µ!
                "threshold_pct": 0.6,  # üî• –ú—è–≥—á–µ!
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º)
                "hold_weight_multiplier": 0.05,  # üî• –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π!
                "long_short_weight_multiplier": 3.0,  # üî• –í—ã—Å–æ–∫–∏–π!
            },
        )
        print(f"      ‚úÖ Accuracy: {rf_metrics['accuracy']:.4f}")
        print(f"      ‚úÖ CV Accuracy: {rf_metrics['cv_mean']:.4f} ¬± {rf_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º XGBoost —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
        print(f"\n   üî• –û–±—É—á–µ–Ω–∏–µ XGBoost...")
        xgb_model, xgb_metrics = trainer.train_xgboost_classifier(
            X, y,
            n_estimators=150,
            max_depth=8,
            learning_rate=0.05,
            class_weight=class_weight_dict,  # üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            xgb_model,
            trainer.scaler,
            feature_names,
            xgb_metrics,
            f"xgb_{symbol}_{interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=interval,
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "n_estimators": 150,
                "max_depth": 8,
                "learning_rate": 0.05,
                "forward_periods": 3,  # üî• –ö–æ—Ä–æ—á–µ!
                "threshold_pct": 0.6,  # üî• –ú—è–≥—á–µ!
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º)
                "hold_weight_multiplier": 0.05,  # üî• –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π!
                "long_short_weight_multiplier": 3.0,  # üî• –í—ã—Å–æ–∫–∏–π!
            },
        )
        print(f"      ‚úÖ Accuracy: {xgb_metrics['accuracy']:.4f}")
        print(f"      ‚úÖ CV Accuracy: {xgb_metrics['cv_mean']:.4f} ¬± {xgb_metrics['cv_std']*2:.4f}")
        
        # –û–±—É—á–∞–µ–º Ensemble (RF + XGBoost)
        print(f"\n   üéØ –û–±—É—á–µ–Ω–∏–µ Ensemble (RF + XGBoost)...")
        ensemble_model, ensemble_metrics = trainer.train_ensemble(
            X, y,
            rf_n_estimators=150,
            rf_max_depth=12,
            xgb_n_estimators=150,
            xgb_max_depth=8,
            xgb_learning_rate=0.05,
            ensemble_method="weighted_average",
            class_weight=class_weight_dict,  # üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞!
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        trainer.save_model(
            ensemble_model,
            trainer.scaler,
            feature_names,
            ensemble_metrics,
            f"ensemble_{symbol}_{interval}_{mode_suffix}.pkl",
            symbol=symbol,
            interval=interval,
            model_type="ensemble_ultra_aggressive",
            class_weights=class_weight_dict,
            class_distribution=target_dist.to_dict(),
            training_params={
                "rf_n_estimators": 150,
                "rf_max_depth": 12,
                "xgb_n_estimators": 150,
                "xgb_max_depth": 8,
                "xgb_learning_rate": 0.05,
                "ensemble_method": "weighted_average",
                "forward_periods": 3,  # üî• –ö–æ—Ä–æ—á–µ!
                "threshold_pct": 0.6,  # üî• –ú—è–≥—á–µ!
                "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º)
                "hold_weight_multiplier": 0.05,  # üî• –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π!
                "long_short_weight_multiplier": 3.0,  # üî• –í—ã—Å–æ–∫–∏–π!
            },
        )
        
        print(f"\n   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ Ensemble:")
        print(f"      CV Accuracy:  {ensemble_metrics['cv_mean']:.4f} ¬± {ensemble_metrics['cv_std']*2:.4f}")
        print(f"      F1-Score:     {ensemble_metrics['f1_score']:.4f}")
        
        # –û–±—É—á–∞–µ–º TripleEnsemble (RF + XGBoost + LightGBM)
        from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
        if LIGHTGBM_AVAILABLE:
            print(f"\n   üî• –û–±—É—á–µ–Ω–∏–µ TripleEnsemble (RF + XGBoost + LightGBM)...")
            triple_ensemble_model, triple_ensemble_metrics = trainer.train_ensemble(
                X, y,
                rf_n_estimators=150,
                rf_max_depth=12,
                xgb_n_estimators=150,
                xgb_max_depth=8,
                xgb_learning_rate=0.05,
                lgb_n_estimators=150,
                lgb_max_depth=8,
                lgb_learning_rate=0.05,
                ensemble_method="triple",
                include_lightgbm=True,
                class_weight=class_weight_dict,  # üî• –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–ê–Ø –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞!
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            trainer.save_model(
                triple_ensemble_model,
                trainer.scaler,
                feature_names,
                triple_ensemble_metrics,
                f"triple_ensemble_{symbol}_{interval}_{mode_suffix}.pkl",
                symbol=symbol,
                interval=interval,
                model_type="triple_ensemble_ultra_aggressive",
                class_weights=class_weight_dict,
                class_distribution=target_dist.to_dict(),
                training_params={
                    "rf_n_estimators": 150,
                    "rf_max_depth": 12,
                    "xgb_n_estimators": 150,
                    "xgb_max_depth": 8,
                    "xgb_learning_rate": 0.05,
                    "lgb_n_estimators": 150,
                    "lgb_max_depth": 8,
                    "lgb_learning_rate": 0.05,
                    "ensemble_method": "triple",
                    "forward_periods": 3,  # üî• –ö–æ—Ä–æ—á–µ!
                    "threshold_pct": 0.6,  # üî• –ú—è–≥—á–µ!
                    "min_risk_reward_ratio": 2.0,  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å 2:1 (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º)
                    "hold_weight_multiplier": 0.05,  # üî• –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π!
                    "long_short_weight_multiplier": 3.0,  # üî• –í—ã—Å–æ–∫–∏–π!
                },
            )
            
            print(f"\n   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ TripleEnsemble:")
            print(f"      CV Accuracy:  {triple_ensemble_metrics['cv_mean']:.4f} ¬± {triple_ensemble_metrics['cv_std']*2:.4f}")
            print(f"      F1-Score:     {triple_ensemble_metrics['f1_score']:.4f}")
            print(f"      Weights:      RF={triple_ensemble_metrics['rf_weight']:.3f}, "
                  f"XGB={triple_ensemble_metrics['xgb_weight']:.3f}, "
                  f"LGB={triple_ensemble_metrics['lgb_weight']:.3f}")
        else:
            print(f"\n   ‚ö†Ô∏è  LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º TripleEnsemble")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    print("\n" + "=" * 80)
    print("üéâ –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–°–ò–í–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    print("\nüì¶ –û–±–Ω–æ–≤–ª–µ–Ω—ã –º–æ–¥–µ–ª–∏:")
    print("   ‚Ä¢ ml_models/rf_*_15.pkl (Random Forest)")
    print("   ‚Ä¢ ml_models/xgb_*_15.pkl (XGBoost)")
    print("   ‚Ä¢ ml_models/ensemble_*_15.pkl (RF + XGBoost)")
    from bot.ml.model_trainer import LIGHTGBM_AVAILABLE
    if LIGHTGBM_AVAILABLE:
        print("   ‚Ä¢ ml_models/triple_ensemble_*_15.pkl (RF + XGBoost + LightGBM)")
    print("\nüî• –û–ñ–ò–î–ê–ï–ú–û–ï –£–õ–£–ß–®–ï–ù–ò–ï:")
    print("   ‚Ä¢ –°–∏–≥–Ω–∞–ª–æ–≤: 15 ‚Üí 100-200 (–≤ 10+ —Ä–∞–∑ –±–æ–ª—å—à–µ!)")
    print("   ‚Ä¢ LONG:  4 ‚Üí 50-100")
    print("   ‚Ä¢ SHORT: 11 ‚Üí 50-100")
    print("\nüß™ –°–õ–ï–î–£–Æ–©–ò–ô –®–ê–ì:")
    print("   python test_ml_strategy.py --symbol SOLUSDT --days 14 --confidence 0.4 --strength —Å–ª–∞–±–æ–µ --no-stability")
    print("\n‚ö†Ô∏è  Win Rate –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å—Å—è (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏)")
    print("=" * 80)

if __name__ == "__main__":
    main()
