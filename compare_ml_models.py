"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –í–°–ï–• ML –º–æ–¥–µ–ª–µ–π –ø–æ –∫–∞–∂–¥–æ–º—É —Å–∏–º–≤–æ–ª—É.

–ó–∞–ø—É—Å–∫–∞–µ—Ç –±—ç–∫—Ç–µ—Å—Ç (—á–µ—Ä–µ–∑ backtest_ml_strategy.run_ml_backtest) –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤
–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ml_models –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python compare_ml_models.py

–û–ø—Ü–∏–∏:
    --days 30           # –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30)
    --symbols BTCUSDT,ETHUSDT,SOLUSDT  # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
    --models-dir ml_models             # –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—è–º–∏
    --output csv                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –≤ CSV
"""

import argparse
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

import pandas as pd

from backtest_ml_strategy import run_ml_backtest, BacktestMetrics


def find_models_for_symbol(models_dir: Path, symbol: str) -> List[Path]:
    """
    –ò—â–µ—Ç –≤—Å–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.
    
    –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞:
        {model_type}_{SYMBOL}_{INTERVAL}.pkl
        {model_type}_{SYMBOL}_{INTERVAL}_{mode_suffix}.pkl  # mtf / 15m
    
    –ü—Ä–∏–º–µ—Ä—ã:
        ensemble_BTCUSDT_15.pkl
        ensemble_BTCUSDT_15_mtf.pkl
        quad_ensemble_ETHUSDT_15_15m.pkl
    """
    if not models_dir.exists():
        return []
    
    patterns = [
        f"*_{symbol}_*.pkl",
    ]
    
    results: List[Path] = []
    for pattern in patterns:
        for f in models_dir.glob(pattern):
            if f.is_file():
                results.append(f)
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏
    results = sorted(list({f.resolve() for f in results}))
    return results


def metrics_to_dict(m: BacktestMetrics) -> Dict[str, Any]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç BacktestMetrics –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∞–Ω–∞–ª–∏–∑–∞."""
    return {
        "symbol": m.symbol,
        "model_name": m.model_name,
        "total_trades": m.total_trades,
        "winning_trades": m.winning_trades,
        "losing_trades": m.losing_trades,
        "win_rate_pct": m.win_rate,
        "total_pnl_usd": m.total_pnl,
        "total_pnl_pct": m.total_pnl_pct,
        "profit_factor": m.profit_factor,
        "max_drawdown_usd": m.max_drawdown,
        "max_drawdown_pct": m.max_drawdown_pct,
        "sharpe_ratio": m.sharpe_ratio,
        "long_trades": m.long_signals,
        "short_trades": m.short_signals,
        "avg_trade_duration_hours": m.avg_trade_duration_hours,
        "avg_win_usd": m.avg_win,
        "avg_loss_usd": m.avg_loss,
        "best_trade_usd": m.best_trade_pnl,
        "worst_trade_usd": m.worst_trade_pnl,
        "largest_win_usd": m.largest_win,
        "largest_loss_usd": m.largest_loss,
        "consecutive_wins": m.consecutive_wins,
        "consecutive_losses": m.consecutive_losses,
        "avg_confidence": m.avg_confidence,
    }


def compare_models(
    symbols: List[str],
    models_dir: Path,
    days: int = 30,
    interval: str = "15m",
    initial_balance: float = 1000.0,
    risk_per_trade: float = 0.02,
    leverage: int = 10,
) -> pd.DataFrame:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –±—ç–∫—Ç–µ—Å—Ç –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
    """
    all_results: List[Dict[str, Any]] = []
    
    print("=" * 80)
    print("üöÄ ML MODELS COMPARISON BACKTEST")
    print("=" * 80)
    print(f"Symbols: {', '.join(symbols)}")
    print(f"Models dir: {models_dir}")
    print(f"Days: {days}, Interval: {interval}, Initial balance: {initial_balance}, Risk per trade: {risk_per_trade*100:.1f}%, Leverage: {leverage}x")
    print("=" * 80)
    
    for symbol in symbols:
        print(f"\n\nüîç SYMBOL: {symbol}")
        print("-" * 80)
        
        models = find_models_for_symbol(models_dir, symbol)
        if not models:
            print(f"‚ùå No models found for {symbol} in {models_dir}")
            continue
        
        print(f"üì¶ Found {len(models)} models for {symbol}:")
        for mpath in models:
            print(f"   - {mpath.name}")
        
        for model_path in models:
            try:
                metrics = run_ml_backtest(
                    model_path=str(model_path),
                    symbol=symbol,
                    days_back=days,
                    interval=interval,
                    initial_balance=initial_balance,
                    risk_per_trade=risk_per_trade,
                    leverage=leverage,
                )
                if metrics is None:
                    print(f"‚ö†Ô∏è  Backtest failed for model {model_path.name}, skipping.")
                    continue
                
                row = metrics_to_dict(metrics)
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –º–æ–¥–µ–ª–∏ –∏ MTF-—Å—É—Ñ—Ñ–∏–∫—Å–µ
                filename = Path(model_path).name
                name_no_ext = filename.replace(".pkl", "")
                parts = name_no_ext.split("_")
                model_type = parts[0] if parts else "unknown"
                mode_suffix = None
                if len(parts) >= 4:
                    mode_suffix = parts[-1]  # mtf / 15m / –¥—Ä.
                row["model_type"] = model_type
                row["mode_suffix"] = mode_suffix or ""
                
                all_results.append(row)
            except Exception as e:
                print(f"‚ùå Exception while backtesting {model_path.name}: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    if not all_results:
        print("‚ùå No results collected.")
        return pd.DataFrame()
    
    df_results = pd.DataFrame(all_results)
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ —Å–∏–º–≤–æ–ª—É, –∑–∞—Ç–µ–º –ø–æ total_pnl_pct (—É–±—ã–≤–∞–Ω–∏–µ)
    df_results.sort_values(
        by=["symbol", "total_pnl_pct", "win_rate_pct"],
        ascending=[True, False, False],
        inplace=True,
    )
    
    return df_results


def print_summary_table(df_results: pd.DataFrame) -> None:
    """–ü–µ—á–∞—Ç–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø–æ –∫–∞–∂–¥–æ–º—É —Å–∏–º–≤–æ–ª—É."""
    if df_results.empty:
        print("‚ùå No results to display.")
        return
    
    print("\n" + "=" * 80)
    print("üìä SUMMARY: BEST MODELS PER SYMBOL")
    print("=" * 80)
    
    for symbol, group in df_results.groupby("symbol"):
        print(f"\nüìà {symbol}:")
        # –ë–µ—Ä—ë–º top-5 –ø–æ PnL%
        top = group.head(5).copy()
        cols = [
            "model_name",
            "model_type",
            "mode_suffix",
            "total_trades",
            "win_rate_pct",
            "total_pnl_usd",
            "total_pnl_pct",
            "profit_factor",
            "max_drawdown_pct",
        ]
        print(top[cols].to_string(index=False, formatters={
            "win_rate_pct": "{:.2f}".format,
            "total_pnl_usd": "{:.2f}".format,
            "total_pnl_pct": "{:+.2f}".format,
            "profit_factor": "{:.2f}".format,
            "max_drawdown_pct": "{:.2f}".format,
        }))


def main():
    parser = argparse.ArgumentParser(description="Compare all ML models via backtesting")
    parser.add_argument("--days", type=int, default=30, help="Days to backtest (default: 30)")
    parser.add_argument(
        "--symbols",
        type=str,
        default="BTCUSDT,ETHUSDT,SOLUSDT",
        help="Comma-separated list of symbols (default: BTCUSDT,ETHUSDT,SOLUSDT)",
    )
    parser.add_argument(
        "--models-dir",
        type=str,
        default="ml_models",
        help="Directory with ML models (default: ml_models)",
    )
    parser.add_argument(
        "--interval",
        type=str,
        default="15m",
        help="Timeframe interval (default: 15m)",
    )
    parser.add_argument(
        "--balance",
        type=float,
        default=1000.0,
        help="Initial balance (default: 1000.0)",
    )
    parser.add_argument(
        "--risk",
        type=float,
        default=0.02,
        help="Risk per trade fraction (default: 0.02 = 2%%)",
    )
    parser.add_argument(
        "--leverage",
        type=int,
        default=10,
        help="Leverage (default: 10)",
    )
    parser.add_argument(
        "--output",
        type=str,
        choices=["none", "csv"],
        default="csv",
        help="Save results to CSV (default: csv)",
    )
    
    args = parser.parse_args()
    
    symbols = [s.strip().upper() for s in args.symbols.split(",") if s.strip()]
    models_dir = Path(args.models_dir)
    
    df_results = compare_models(
        symbols=symbols,
        models_dir=models_dir,
        days=args.days,
        interval=args.interval,
        initial_balance=args.balance,
        risk_per_trade=args.risk,
        leverage=args.leverage,
    )
    
    if df_results.empty:
        return
    
    # –ü–µ—á–∞—Ç–∞–µ–º —Å–≤–æ–¥–∫—É
    print_summary_table(df_results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    if args.output == "csv":
        output_name = f"ml_models_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df_results.to_csv(output_name, index=False)
        print(f"\nüíæ Full comparison table saved to: {output_name}")


if __name__ == "__main__":
    main()

