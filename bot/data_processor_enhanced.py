import numpy as np
import pandas as pd
import warnings
from typing import Tuple, List, Dict, Optional
from scipy import stats
import talib
from sklearn.preprocessing import RobustScaler
warnings.filterwarnings('ignore')


class DataProcessorEnhanced:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ TP-–ø—Ä–∏–∑–Ω–∞–∫–∏"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.raw_df = None
        self.processed_df = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è TP-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.atr_period = 14
        self.rsi_period = 14
        self.bb_period = 20
        self.macd_fast = 12
        self.macd_slow = 26
        self.macd_signal = 9
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        self.scalers = {}
        self.feature_stats = {}
        
    def load_data(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        print(f"\nüì• –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò–ó: {self.data_path}")
        
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            if self.data_path.endswith('.csv'):
                df = pd.read_csv(self.data_path)
            elif self.data_path.endswith('.parquet'):
                df = pd.read_parquet(self.data_path)
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {self.data_path}")
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['open', 'high', 'low', 'close']
            if not all(col in df.columns for col in required_cols):
                print(f"‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏")
                print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å
                rename_map = {}
                for req in required_cols:
                    if req.upper() in df.columns:
                        rename_map[req.upper()] = req
                    elif req.capitalize() in df.columns:
                        rename_map[req.capitalize()] = req
                
                if rename_map:
                    df = df.rename(columns=rename_map)
                    print(f"   –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ: {rename_map}")
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if not all(col in df.columns for col in required_cols):
                print("‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏")
                # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                print("üìù –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
                df = pd.DataFrame({
                    'open': np.random.normal(100, 5, 1000),
                    'high': np.random.normal(105, 5, 1000),
                    'low': np.random.normal(95, 5, 1000),
                    'close': np.random.normal(100, 5, 1000),
                    'volume': np.random.normal(1000, 100, 1000)
                })
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            max_rows = 100000  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            if len(df) > max_rows:
                print(f"‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö ({len(df)} —Å—Ç—Ä–æ–∫), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é –¥–æ {max_rows}")
                df = df.iloc[-max_rows:].copy()
            
            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ (–Ω–µ —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏!)
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col in df.columns:
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –±–µ–∑–æ–ø–∞—Å–Ω–æ
                    df[col] = df[col].ffill().bfill().fillna(0)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ (–º—è–≥–∫–∞—è)
                    if col in ['open', 'high', 'low', 'close', 'volume']:
                        q1 = df[col].quantile(0.01)
                        q3 = df[col].quantile(0.99)
                        iqr = q3 - q1
                        lower_bound = q1 - 3 * iqr
                        upper_bound = q3 + 3 * iqr
                        
                        outliers_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
                        if outliers_mask.any():
                            print(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ {col}: {outliers_mask.sum()} —Ç–æ—á–µ–∫")
                            df.loc[outliers_mask, col] = df[col].median()
            
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            self.raw_df = df.reset_index(drop=True).copy()
            return self.raw_df
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            print("üìù –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            self.raw_df = pd.DataFrame({
                'open': np.linspace(100, 200, 1000),
                'high': np.linspace(105, 205, 1000),
                'low': np.linspace(95, 195, 1000),
                'close': np.linspace(100, 200, 1000),
                'volume': np.random.normal(1000, 100, 1000)
            })
            return self.raw_df
    
    def check_data_quality(self) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if self.raw_df is None:
            return {'error': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}
        
        total_rows = len(self.raw_df)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        missing_values = self.raw_df.isnull().sum().sum()
        missing_percentage = (missing_values / (total_rows * len(self.raw_df.columns))) * 100
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–Ω
        price_cols = [col for col in ['open', 'high', 'low', 'close'] if col in self.raw_df.columns]
        negative_prices = 0
        if price_cols:
            negative_prices = (self.raw_df[price_cols] < 0).any(axis=1).sum()
        
        return {
            'total_rows': total_rows,
            'missing_values': int(missing_values),
            'missing_percentage': missing_percentage,
            'negative_prices': int(negative_prices)
        }
    
    def prepare_features(self) -> pd.DataFrame:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ - –£–ü–†–û–©–ï–ù–ù–´–ô –î–õ–Ø –°–ö–û–†–û–°–¢–ò"""
        if self.raw_df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
            return pd.DataFrame()
        
        print("\n" + "="*60)
        print("–†–ê–°–ß–ï–¢ –ü–†–ò–ó–ù–ê–ö–û–í (–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)")
        print("="*60)
        
        df = self.raw_df.copy()
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        quality = self.check_data_quality()
        print(f"–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {quality['total_rows']:,} —Å—Ç—Ä–æ–∫, "
              f"–ø—Ä–æ–ø—É—Å–∫–æ–≤: {quality['missing_values']} ({quality['missing_percentage']:.2f}%)")
        
        # 1. –ë–ê–ó–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò (—Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ)
        print("\n--- –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ---")
        df = self._add_basic_features(df)
        
        # 2. –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
        print("--- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ---")
        df = self._add_technical_indicators_simple(df)
        
        # 3. TP-–û–†–ò–ï–ù–¢–ò–†–û–í–ê–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ!)
        print("--- TP-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ---")
        df = self._add_tp_oriented_features(df)
        
        # 4. –ü–†–û–°–¢–ê–Ø –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø (–±–µ–∑ –æ–∫–æ–Ω!)
        print("--- –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ---")
        df = self._simple_normalization(df)
        
        # 5. –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê
        print("--- –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ ---")
        df = self._final_cleanup(df)
        
        print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
        print(f"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫ √ó {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        
        self.processed_df = df
        return df
    
    def _add_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        df['log_ret'] = np.log(df['close'] / df['close'].shift(1))
        df['log_ret'] = df['log_ret'].fillna(0)
        
        # –ü—Ä–æ—Å—Ç–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        df['returns'] = df['close'].pct_change()
        df['returns'] = df['returns'].fillna(0)
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (–ø—Ä–æ—Å—Ç–∞—è)
        df['volatility'] = df['returns'].rolling(window=20, min_periods=1).std()
        df['volatility'] = df['volatility'].fillna(df['volatility'].mean())
        
        # –í—ã—Å–æ–∫–∏–µ/–Ω–∏–∑–∫–∏–µ
        df['high_low_ratio'] = df['high'] / df['low']
        df['close_open_ratio'] = df['close'] / df['open']
        
        # –û–±—ä–µ–º
        if 'volume' in df.columns:
            df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20, min_periods=1).mean()
            df['volume_ratio'] = df['volume_ratio'].fillna(1)
        
        print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 6")
        return df
    
    def _add_technical_indicators_simple(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        try:
            # RSI (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=self.rsi_period, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=self.rsi_period, min_periods=1).mean()
            rs = gain / (loss + 1e-10)
            df['rsi'] = 100 - (100 / (1 + rs))
            df['rsi'] = df['rsi'].fillna(50)
            
            # ATR (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            high_low = df['high'] - df['low']
            high_close = np.abs(df['high'] - df['close'].shift())
            low_close = np.abs(df['low'] - df['close'].shift())
            tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            df['atr'] = tr.rolling(window=self.atr_period, min_periods=1).mean()
            df['atr'] = df['atr'].fillna(df['atr'].mean())
            
            # Bollinger Bands (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            df['sma_20'] = df['close'].rolling(window=20, min_periods=1).mean()
            rolling_std = df['close'].rolling(window=20, min_periods=1).std()
            df['bb_upper'] = df['sma_20'] + (rolling_std * 2)
            df['bb_lower'] = df['sma_20'] - (rolling_std * 2)
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)
            
            # Momentum
            df['momentum'] = df['close'] - df['close'].shift(5)
            df['momentum'] = df['momentum'].fillna(0)
            
            # ADX (–æ—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            plus_dm = df['high'].diff()
            minus_dm = df['low'].diff().abs()
            tr = high_low.combine(high_close.combine(low_close, max), max)
            plus_di = 100 * (plus_dm.rolling(window=14).mean() / tr.rolling(window=14).mean())
            minus_di = 100 * (minus_dm.rolling(window=14).mean() / tr.rolling(window=14).mean())
            df['adx'] = 100 * abs(plus_di - minus_di) / (plus_di + minus_di + 1e-10)
            df['adx'] = df['adx'].fillna(df['adx'].mean())
            
            print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: 7")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
        
        return df
    
    def _add_tp_oriented_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ TP-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ - –£–ü–†–û–©–ï–ù–ù–´–•!"""
        print("   –†–∞—Å—á–µ—Ç TP/SL –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ë–∞–∑–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è TP/SL
        if 'atr' not in df.columns:
            df['atr'] = (df['high'] - df['low']).rolling(window=14, min_periods=1).mean()
        
        base_atr = df['atr'].fillna(df['atr'].mean())
        current_price = df['close']
        
        # –£–ü–†–û–©–ï–ù–ù–´–ï TP-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ª–æ–Ω–≥–æ–≤ (3 —É—Ä–æ–≤–Ω—è)
        for i, multiplier in enumerate([1.2, 1.8, 2.4], 1):
            tp_distance = base_atr * multiplier
            df[f'tp_up_atr_{i}'] = tp_distance / current_price  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
            
            # –ü—Ä–∏–∑–Ω–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ TP (–æ—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            if 'rsi' in df.columns:
                # –ï—Å–ª–∏ RSI < 40 (–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å), –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å TP
                rsi_factor = np.where(df['rsi'] < 40, 1.5, 
                                    np.where(df['rsi'] > 70, 0.7, 1.0))
                df[f'tp_up_prob_{i}'] = 0.5 * rsi_factor
            else:
                df[f'tp_up_prob_{i}'] = 0.5
        
        # –£–ü–†–û–©–ï–ù–ù–´–ï TP-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —à–æ—Ä—Ç–æ–≤
        for i, multiplier in enumerate([1.2, 1.8, 2.4], 1):
            tp_distance = base_atr * multiplier
            df[f'tp_down_atr_{i}'] = -tp_distance / current_price  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è —à–æ—Ä—Ç–æ–≤
            
            if 'rsi' in df.columns:
                # –ï—Å–ª–∏ RSI > 60 (–ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å), –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å TP –¥–ª—è —à–æ—Ä—Ç–æ–≤
                rsi_factor = np.where(df['rsi'] > 60, 1.5,
                                    np.where(df['rsi'] < 30, 0.7, 1.0))
                df[f'tp_down_prob_{i}'] = 0.5 * rsi_factor
            else:
                df[f'tp_down_prob_{i}'] = 0.5
        
        # –£–ü–†–û–©–ï–ù–ù–´–ï SL-–ø—Ä–∏–∑–Ω–∞–∫–∏
        sl_multiplier = 1.5  # RR=2: TP 1.2 / SL 0.6 = 2.0
        
        # SL –¥–ª—è –ª–æ–Ω–≥–æ–≤
        sl_distance_long = base_atr * sl_multiplier
        df['sl_up_atr'] = -sl_distance_long / current_price  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ
        
        # SL –¥–ª—è —à–æ—Ä—Ç–æ–≤
        sl_distance_short = base_atr * sl_multiplier
        df['sl_down_atr'] = sl_distance_short / current_price  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≤—ã—Ö–æ–¥–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
        df['time_since_high'] = df['close'].rolling(window=20, min_periods=1).apply(
            lambda x: len(x) - np.argmax(x) - 1 if len(x) > 0 else 0, raw=False
        )
        df['time_since_low'] = df['close'].rolling(window=20, min_periods=1).apply(
            lambda x: len(x) - np.argmin(x) - 1 if len(x) > 0 else 0, raw=False
        )
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫ TP
        for i in range(1, 4):
            df[f'progress_to_tp_up_{i}'] = (df['close'] - df['close'].shift(1)) / (base_atr * [1.2, 1.8, 2.4][i-1] + 1e-10)
            df[f'progress_to_tp_down_{i}'] = (df['close'].shift(1) - df['close']) / (base_atr * [1.2, 1.8, 2.4][i-1] + 1e-10)
        
        print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ TP/SL –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 18")
        return df
    
    def _simple_normalization(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –æ–∫–æ–Ω - –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!"""
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è {len(df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø—Ä–æ—Å—Ç–∞—è)")
        
        # –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        cols_to_normalize = [
            'log_ret', 'returns', 'volatility', 'high_low_ratio', 
            'close_open_ratio', 'volume_ratio', 'rsi', 'atr',
            'bb_position', 'momentum', 'adx'
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º TP/SL –ø—Ä–∏–∑–Ω–∞–∫–∏
        tp_cols = [col for col in df.columns if 'tp_' in col or 'sl_' in col or 'prob_' in col or 'progress_' in col]
        cols_to_normalize.extend(tp_cols)
        
        # –¢–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
        cols_to_normalize = [col for col in cols_to_normalize if col in df.columns]
        
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (z-score)
        for col in cols_to_normalize:
            try:
                mean_val = df[col].mean()
                std_val = df[col].std()
                if std_val > 1e-10:
                    df[f'{col}_norm'] = (df[col] - mean_val) / std_val
                else:
                    df[f'{col}_norm'] = 0
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
                df[f'{col}_norm'] = df[f'{col}_norm'].clip(-5, 5)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ {col}: {e}")
                df[f'{col}_norm'] = 0
        
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(cols_to_normalize)}")
        return df
    
    def _final_cleanup(self, df: pd.DataFrame) -> pd.DataFrame:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN
        df = df.fillna(0)
        
        # –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        df = df.replace([np.inf, -np.inf], 0)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–ª–æ–Ω–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        df = df.loc[:, ~df.columns.duplicated()]
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        min_rows = 100
        if len(df) < min_rows:
            print(f"‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(df)}")
            # –î—É–±–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            while len(df) < min_rows:
                df = pd.concat([df, df], ignore_index=True)
            df = df.iloc[:min_rows]
            print(f"   –†–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ {len(df)} —Å—Ç—Ä–æ–∫")
        
        return df
    
    def split_data(self, test_size: float = 0.1, validation_size: float = 0.1) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/val/test"""
        if self.processed_df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            empty_df = pd.DataFrame()
            return empty_df, empty_df, empty_df
        
        df = self.processed_df.copy()
        n = len(df)
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        val_split = int(n * (1 - test_size - validation_size))
        test_split = int(n * (1 - test_size))
        
        train_df = df.iloc[:val_split].copy()
        val_df = df.iloc[val_split:test_split].copy()
        test_df = df.iloc[test_split:].copy()
        
        print(f"\nüìä –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•:")
        print(f"   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {n:,}")
        print(f"   Train: {len(train_df):,} —Å—Ç—Ä–æ–∫ ({len(train_df)/n*100:.1f}%)")
        print(f"   Validation: {len(val_df):,} —Å—Ç—Ä–æ–∫ ({len(val_df)/n*100:.1f}%)")
        print(f"   Test: {len(test_df):,} —Å—Ç—Ä–æ–∫ ({len(test_df)/n*100:.1f}%)")
        
        return train_df, val_df, test_df
    
    def get_observation_columns(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è"""
        if self.processed_df is None:
            print("‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞—é –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            return []
        
        # –ë–µ—Ä–µ–º –≤—Å–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        norm_cols = [col for col in self.processed_df.columns if col.endswith('_norm')]
        
        # –ò –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∞–∂–Ω—ã–µ –Ω–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
        important_cols = []
        for col in ['rsi', 'atr', 'bb_position', 'volatility']:
            if col in self.processed_df.columns and f'{col}_norm' not in norm_cols:
                important_cols.append(col)
        
        all_cols = norm_cols + important_cols
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        all_cols = list(dict.fromkeys(all_cols))
        
        print(f"\nüìã –ö–û–õ–û–ù–ö–ò –î–õ–Ø –ù–ê–ë–õ–Æ–î–ï–ù–ò–Ø:")
        print(f"   –í—Å–µ–≥–æ: {len(all_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"   TP/SL –ø—Ä–∏–∑–Ω–∞–∫–∏: {len([c for c in all_cols if 'tp_' in c or 'sl_' in c])}")
        
        return all_cols
    
    def get_tp_related_features(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ TP-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if self.processed_df is None:
            return []
        
        tp_features = [
            col for col in self.processed_df.columns 
            if any(x in col for x in ['tp_', 'sl_', 'prob_', 'progress_'])
        ]
        
        return tp_features
    
    def get_exit_timing_features(self) -> List[str]:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–∞"""
        if self.processed_df is None:
            return []
        
        exit_features = [
            col for col in self.processed_df.columns 
            if any(x in col for x in ['time_', 'since_', 'duration', 'hold'])
        ]
        
        return exit_features
    
    def get_volatility_features(self) -> List[str]:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
        if self.processed_df is None:
            return []
        
        vol_features = [
            col for col in self.processed_df.columns 
            if any(x in col for x in ['volatility', 'atr', 'std', 'range'])
        ]
        
        return vol_features


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    processor = DataProcessorEnhanced("data/btc_15m.csv")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = processor.load_data()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    quality = processor.check_data_quality()
    print(f"\n–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {quality}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    processed_df = processor.prepare_features()
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
    print(f"   –°—Ç—Ä–æ–∫: {len(processed_df)}")
    print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(processed_df.columns)}")
    print(f"   –ü—Ä–∏–º–µ—Ä –∫–æ–ª–æ–Ω–æ–∫: {list(processed_df.columns[:10])}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è
    obs_cols = processor.get_observation_columns()
    print(f"\n   –ö–æ–ª–æ–Ω–æ–∫ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è: {len(obs_cols)}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    train_df, val_df, test_df = processor.split_data()
    print(f"\n   –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: train={len(train_df)}, val={len(val_df)}, test={len(test_df)}")