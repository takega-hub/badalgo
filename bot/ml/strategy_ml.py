"""
ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é ML-–º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.
"""
import warnings
import os

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è scikit-learn –î–û –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –ü–ï–†–í–û–ô
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
os.environ['SKLEARN_WARNINGS'] = 'ignore'

# –§–∏–ª—å—Ç—Ä—É–µ–º –≤—Å–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è sklearn
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', module='sklearn')
warnings.filterwarnings('ignore', message='.*sklearn.*')
warnings.filterwarnings('ignore', message='.*parallel.*')
warnings.filterwarnings('ignore', message='.*delayed.*')
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.*')
warnings.filterwarnings('ignore', message='.*should be used with.*')
warnings.filterwarnings('ignore', message='.*propagate the scikit-learn configuration.*')
# –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.delayed.*')

import pickle
from pathlib import Path
from typing import Optional, Dict, Any

import numpy as np
import pandas as pd

from bot.strategy import Action, Bias, Signal
from bot.ml.feature_engineering import FeatureEngineer
from bot.config import StrategyParams
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –∞–Ω—Å–∞–º–±–ª—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pickle
from bot.ml.model_trainer import PreTrainedVotingEnsemble, WeightedEnsemble


class MLStrategy:
    """
    ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã.
    """
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.5, min_signal_strength: str = "—Å–ª–∞–±–æ–µ", stability_filter: bool = True, use_dynamic_threshold: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—é.
        
        Args:
            model_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pkl —Ñ–∞–π–ª)
            confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏ (0-1)
            min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ ("—Å–ª–∞–±–æ–µ", "—É–º–µ—Ä–µ–Ω–Ω–æ–µ", "—Å—Ä–µ–¥–Ω–µ–µ", "—Å–∏–ª—å–Ω–æ–µ", "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ")
            stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            use_dynamic_threshold: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
        """
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.min_signal_strength = min_signal_strength
        self.stability_filter = stability_filter
        self.use_dynamic_threshold = use_dynamic_threshold
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞
        strength_thresholds = {
            "—Å–ª–∞–±–æ–µ": 0.0,
            "—É–º–µ—Ä–µ–Ω–Ω–æ–µ": 0.6,
            "—Å—Ä–µ–¥–Ω–µ–µ": 0.7,
            "—Å–∏–ª—å–Ω–æ–µ": 0.8,
            "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ": 0.9
        }
        self.min_strength_threshold = strength_thresholds.get(min_signal_strength, 0.6)
        
        # –ò—Å—Ç–æ—Ä–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
        self.confidence_history = []
        self.max_history_size = 100
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.model_data = self._load_model()
        self.model = self.model_data["model"]
        self.scaler = self.model_data["scaler"]
        self.feature_names = self.model_data["feature_names"]
        self.is_ensemble = self.model_data.get("metadata", {}).get("model_type", "").startswith("ensemble")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º feature engineer
        self.feature_engineer = FeatureEngineer()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        model_filename = Path(model_path).name
        symbol_from_model = "UNKNOWN"
        if "_" in model_filename:
            parts = model_filename.split("_")
            if len(parts) >= 2:
                symbol_from_model = parts[1]  # –ù–∞–ø—Ä–∏–º–µ—Ä, rf_ETHUSDT_15.pkl -> ETHUSDT
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        model_metadata = self.model_data.get("metadata", {})
        model_type_str = model_metadata.get("model_type", "unknown")
        if "ensemble" in model_type_str.lower():
            self.is_ensemble = True
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –ª–æ–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ)
        if not hasattr(self, '_model_loaded_logged'):
            model_type = 'üéØ ENSEMBLE' if self.is_ensemble else 'Single'
            cv_acc = self.model_data.get("metrics", {}).get('cv_mean', 0) if self.is_ensemble else 0
            print(f"[ml] {symbol_from_model}: {model_type} (CV:{cv_acc:.3f}, conf:{confidence_threshold}, stab:{stability_filter})")
            self._model_loaded_logged = True
    
    def _load_model(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞."""
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        
        with open(self.model_path, "rb") as f:
            model_data = pickle.load(f)
        
        return model_data
    
    def prepare_features(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> np.ndarray:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ DataFrame –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∏—á–∏)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            –ú–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        # –ï—Å–ª–∏ —Ñ–∏—á–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã (skip_feature_creation=True), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
        if skip_feature_creation:
            df_with_features = df.copy()
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∑–∞–Ω–æ–≤–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ timestamp –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ (–Ω—É–∂–Ω–æ –¥–ª—è feature_engineer)
            df_work = df.copy()
            if "timestamp" in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                df_work = df_work.set_index("timestamp")
            elif "timestamp" not in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                if isinstance(df_work.index, pd.DatetimeIndex):
                    pass  # –£–∂–µ DatetimeIndex
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
                    df_work.index = pd.to_datetime(df_work.index, errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏—á–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            print(f"[ml_strategy] Preparing features: input DataFrame has {len(df_work)} rows")
            try:
                df_with_features = self.feature_engineer.create_technical_indicators(df_work)
                print(f"[ml_strategy] After create_technical_indicators: {len(df_with_features)} rows, {len(df_with_features.columns)} columns")
            except TypeError as e:
                if "'>' not supported" in str(e) or "NoneType" in str(e):
                    print(f"[ml_strategy] ‚ùå ERROR: Comparison with None detected in create_technical_indicators")
                    print(f"[ml_strategy]   Error: {e}")
                    print(f"[ml_strategy]   Checking for None values in DataFrame...")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ None –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
                    for col in ["open", "high", "low", "close", "volume", "atr", "atr_pct", "rsi"]:
                        if col in df_work.columns:
                            none_count = df_work[col].isna().sum() + (df_work[col] == None).sum()
                            if none_count > 0:
                                print(f"[ml_strategy]   Column '{col}' has {none_count} None/NaN values")
                    raise
                raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OHLCV)
        key_columns = ["open", "high", "low", "close", "volume"]
        if all(col in df_with_features.columns for col in key_columns):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            rows_before = len(df_with_features)
            df_with_features = df_with_features[df_with_features[key_columns].notna().any(axis=1)]
            rows_after = len(df_with_features)
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ò —ç—Ç–æ –Ω–µ skip_feature_creation (—á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ª–æ–≥–∏)
            if not skip_feature_creation and rows_before != rows_after:
                print(f"[ml_strategy] After filtering key columns: {rows_before} -> {rows_after} rows")
        else:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ skip_feature_creation
            if not skip_feature_creation:
                missing_key_cols = [col for col in key_columns if col not in df_with_features.columns]
                print(f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing key columns: {missing_key_cols}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        if len(df_with_features) == 0:
            print(f"[ml_strategy] ‚ùå ERROR: No rows after filtering key columns")
            print(f"[ml_strategy]   Input DataFrame shape: {df_work.shape}")
            print(f"[ml_strategy]   After create_technical_indicators shape: {df_with_features.shape if 'df_with_features' in locals() else 'N/A'}")
            raise ValueError("No data available after creating features (all rows contain NaN in key columns)")
        
        # –í–ê–ñ–ù–û: –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Ñ–∏—á–∞—Ö –Ω—É–ª—è–º–∏ –ü–ï–†–ï–î –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –≤—ã—á–∏—Å–ª–∏–ª–∏—Å—å
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞—Ö (–Ω–æ –Ω–µ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö)
        feature_columns = [col for col in df_with_features.columns if col not in key_columns]
        if feature_columns:
            df_with_features[feature_columns] = df_with_features[feature_columns].fillna(0)
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏) NaN
        df_with_features = df_with_features.dropna(how='all')
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if len(df_with_features) == 0:
            raise ValueError("No data available after creating features (all rows contain NaN)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∏—á–µ–π
        missing_features = [f for f in self.feature_names if f not in df_with_features.columns]
        if missing_features:
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏
            if not hasattr(self, '_missing_features_warned'):
                print(f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing {len(missing_features)} features: {missing_features[:10]}...")
                print(f"[ml_strategy]   Expected {len(self.feature_names)} features, got {len(df_with_features.columns)}")
                self._missing_features_warned = True
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏ –Ω—É–ª—è–º–∏
            for missing_feat in missing_features:
                df_with_features[missing_feat] = 0.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∏—á–∏ (–∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –Ω–µ –æ–∂–∏–¥–∞—é—Ç—Å—è –º–æ–¥–µ–ª—å—é)
        extra_features = [f for f in df_with_features.columns if f not in self.feature_names and f not in key_columns]
        # –£–±–∏—Ä–∞–µ–º –ª–æ–≥–∏ –æ –ª–∏—à–Ω–∏—Ö —Ñ–∏—á–∞—Ö - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è (–æ–Ω–∏ –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
        if extra_features:
            self._extra_features_warned = True  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, –Ω–æ –Ω–µ –ª–æ–≥–∏—Ä—É–µ–º
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        X = df_with_features[self.feature_names].values
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if len(X) == 0:
            raise ValueError("No data available after feature selection")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π —Å –º–æ–¥–µ–ª—å—é
        if X.shape[1] != len(self.feature_names):
            raise ValueError(f"Feature count mismatch: X has {X.shape[1]} features, but model expects {len(self.feature_names)}")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
        except ValueError as e:
            if "features" in str(e).lower() or "n_features" in str(e).lower():
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π
                scaler_expected = getattr(self.scaler, 'n_features_in_', None)
                if scaler_expected is None:
                    # –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è sklearn - –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ shape
                    try:
                        scaler_expected = self.scaler.mean_.shape[0] if hasattr(self.scaler, 'mean_') else None
                    except:
                        pass
                
                if scaler_expected and X.shape[1] != scaler_expected:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è)
                    if not hasattr(self, '_feature_mismatch_warned'):
                        self._feature_mismatch_warned = True
                    
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –±–æ–ª—å—à–µ —Ñ–∏—á–µ–π, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω—É–ª—è–º–∏
                    if X.shape[1] < scaler_expected:
                        missing_count = scaler_expected - X.shape[1]
                        if not hasattr(self, '_feature_adjustment_logged'):
                            self._feature_adjustment_logged = True
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                        zeros = np.zeros((X.shape[0], missing_count))
                        X = np.hstack([X, zeros])
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –º–µ–Ω—å—à–µ —Ñ–∏—á–µ–π, –æ–±—Ä–µ–∑–∞–µ–º
                    elif X.shape[1] > scaler_expected:
                        X = X[:, :scaler_expected]
                
                # –ü—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                try:
                    X_scaled = self.scaler.transform(X)
                except ValueError as e2:
                    print(f"[ml_strategy] ‚ùå ERROR: Still cannot transform after adjustment")
                    print(f"[ml_strategy]   Scaler expects: {scaler_expected} features")
                    print(f"[ml_strategy]   X has: {X.shape[1]} features")
                    raise ValueError(f"Feature count mismatch: Scaler expects {scaler_expected} features, but got {X.shape[1]}. "
                                   f"Please retrain the model with the current feature set.") from e2
            else:
                raise
        
        return X_scaled
    
    def predict(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> tuple[int, float]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–∞—Ä–∞.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (OHLCV, —Ñ–∏—á–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–ª–∏ —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            (prediction, confidence) –≥–¥–µ:
            - prediction: 1 (LONG), -1 (SHORT), 0 (HOLD)
            - confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0-1)
        """
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ä
        if len(df) == 0:
            return 0, 0.0
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏ (—Å–æ–∑–¥–∞—Å—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ)
            X = self.prepare_features(df, skip_feature_creation=skip_feature_creation)
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–∑–µ—Ü
            X_last = X[-1:].reshape(1, -1)
        except Exception as e:
            print(f"[ml_strategy] Error preparing features: {e}")
            return 0, 0.0
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if hasattr(self.model, "predict_proba"):
            # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (–≤–∫–ª—é—á–∞—è –∞–Ω—Å–∞–º–±–ª—å)
            proba = self.model.predict_proba(X_last)[0]
            
            # –î–ª—è –∞–Ω—Å–∞–º–±–ª—è proba —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
            # –î–ª—è XGBoost –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–∑ [0, 1, 2]
            if self.is_ensemble:
                # –ê–Ω—Å–∞–º–±–ª—å —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1  # 0->-1, 1->0, 2->1
                confidence = proba[prediction_idx]
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç HOLD, –Ω–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if self.use_dynamic_threshold and len(self.confidence_history) > 10:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π
                    recent_confidence_median = np.median(self.confidence_history[-20:])
                    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –º–µ–¥–∏–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                    adaptive_threshold = max(self.min_strength_threshold, recent_confidence_median * 0.9)
                else:
                    adaptive_threshold = self.min_strength_threshold
                
                # –ï—Å–ª–∏ HOLD –∏–º–µ–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, –Ω–æ LONG –∏–ª–∏ SHORT –∏–º–µ—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ (–µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–≤—ã—à–∞—é—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥)
                if prediction == 0:  # HOLD
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è HOLD
                    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT >= adaptive_threshold, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º HOLD
                    if long_prob >= adaptive_threshold and long_prob > short_prob:
                        prediction = 1  # LONG
                        confidence = long_prob
                    elif short_prob >= adaptive_threshold and short_prob > long_prob:
                        prediction = -1  # SHORT
                        confidence = short_prob
                    # –ò–Ω–∞—á–µ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ HOLD
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            elif len(proba) == 3:
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1  # 0->-1, 1->0, 2->1
                confidence = proba[prediction_idx]
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç HOLD, –Ω–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if self.use_dynamic_threshold and len(self.confidence_history) > 10:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π
                    recent_confidence_median = np.median(self.confidence_history[-20:])
                    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –º–µ–¥–∏–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                    adaptive_threshold = max(self.min_strength_threshold, recent_confidence_median * 0.9)
                else:
                    adaptive_threshold = self.min_strength_threshold
                
                # –ï—Å–ª–∏ HOLD –∏–º–µ–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, –Ω–æ LONG –∏–ª–∏ SHORT –∏–º–µ—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ (–µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–≤—ã—à–∞—é—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥)
                if prediction == 0:  # HOLD
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è HOLD
                    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT >= adaptive_threshold, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º HOLD
                    if long_prob >= adaptive_threshold and long_prob > short_prob:
                        prediction = 1  # LONG
                        confidence = long_prob
                    elif short_prob >= adaptive_threshold and short_prob > long_prob:
                        prediction = -1  # SHORT
                        confidence = short_prob
                    # –ò–Ω–∞—á–µ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ HOLD
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1 if len(proba) == 3 else prediction_idx
                confidence = proba[prediction_idx]
        else:
            # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ predict_proba
            prediction_raw = self.model.predict(X_last)[0]
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç -1, 0, 1 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if hasattr(self.model, 'classes_'):
                # –ï—Å–ª–∏ –µ—Å—Ç—å classes_, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –∑–Ω–∞—á–µ–Ω–∏–µ
                classes = self.model.classes_
                if len(classes) == 3:
                    prediction = int(prediction_raw) - 1  # 0->-1, 1->0, 2->1
                else:
                    prediction = int(prediction_raw)
            else:
                prediction = int(prediction_raw)
            confidence = 1.0  # –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        return int(prediction), float(confidence)
    
    def generate_signal(
        self,
        row: pd.Series,
        df: pd.DataFrame,
        has_position: Optional[Bias],
        current_price: float,
        leverage: int = 10,
        target_profit_pct_margin: float = 25.0,
        max_loss_pct_margin: float = 10.0,
    ) -> Signal:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
        
        Args:
            row: –¢–µ–∫—É—â–∏–π –±–∞—Ä (pd.Series)
            df: DataFrame —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏—á–µ–π)
            has_position: –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è (None, Bias.LONG, Bias.SHORT)
            current_price: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            leverage: –ü–ª–µ—á–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ TP/SL
            target_profit_pct_margin: –¶–µ–ª–µ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ –≤ % (20-30%)
            max_loss_pct_margin: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫ –æ—Ç –º–∞—Ä–∂–∏ –≤ %
        
        Returns:
            Signal –æ–±—ä–µ–∫—Ç
        """
        try:
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã –≤ build_ml_signals)
            prediction, confidence = self.predict(df, skip_feature_creation=True)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º TP/SL –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç —Ü–µ–Ω—ã –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏ –æ—Ç –º–∞—Ä–∂–∏
            # –ï—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ = 25%, –∞ –ø–ª–µ—á–æ = 10x, —Ç–æ TP = 25% / 10 = 2.5%
            tp_pct = target_profit_pct_margin / leverage
            sl_pct = max_loss_pct_margin / leverage
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if confidence >= 0.9:
                strength = "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.8:
                strength = "—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.7:
                strength = "—Å—Ä–µ–¥–Ω–µ–µ"
            elif confidence >= 0.6:
                strength = "—É–º–µ—Ä–µ–Ω–Ω–æ–µ"
            else:
                strength = "—Å–ª–∞–±–æ–µ"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω—É—é –ø—Ä–∏—á–∏–Ω—É
            confidence_pct = int(confidence * 100)
            profit_pct = int(target_profit_pct_margin)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å–∏–ª—É —Å–∏–≥–Ω–∞–ª–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è LONG/SHORT, –Ω–µ –¥–ª—è HOLD)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ min_strength_threshold –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–ª–∞–±—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            if prediction != 0 and confidence < self.min_strength_threshold:
                # –°–∏–≥–Ω–∞–ª –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å–∏–ª—ã - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º HOLD
                return Signal(row.name, Action.HOLD, f"ml_—Å–∏–ª–∞_—Å–ª–∏—à–∫–æ–º_—Å–ª–∞–±–∞—è_{strength}_{confidence_pct}%_–º–∏–Ω_{int(self.min_strength_threshold*100)}%", current_price)
            
            # === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ===
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            volume = row.get("volume", np.nan)
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å vol_sma –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            # –í –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ prepare_with_indicators –µ—Å—Ç—å vol_sma
            # –í –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ FeatureEngineer –µ—Å—Ç—å volume_sma_20
            vol_sma = row.get("vol_sma", np.nan)
            if not np.isfinite(vol_sma):
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º volume_sma_20 –∏–∑ —Ñ–∏—á–µ–π FeatureEngineer
                vol_sma = row.get("volume_sma_20", np.nan)
            if not np.isfinite(vol_sma):
                # –ï—Å–ª–∏ vol_sma –≤—Å–µ –µ—â–µ –Ω–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Å—Ç—É—é SMA –∑–∞ 20 –ø–µ—Ä–∏–æ–¥–æ–≤ –∏–∑ df
                try:
                    if len(df) >= 20:
                        vol_sma = df["volume"].rolling(window=20).mean().iloc[-1]
                except:
                    pass
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞: –µ—Å–ª–∏ vol_sma –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Å—á–∏—Ç–∞–µ–º –æ–±—ä–µ–º OK
            # –ï—Å–ª–∏ vol_sma –¥–æ—Å—Ç—É–ø–µ–Ω, —Ç—Ä–µ–±—É–µ–º —Ç–æ–ª—å–∫–æ 50% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ (–≤–º–µ—Å—Ç–æ 80%)
            if not np.isfinite(vol_sma):
                volume_ok = True  # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ä–µ–¥–Ω–µ–º –æ–±—ä–µ–º–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª
            else:
                volume_ok = np.isfinite(volume) and volume > vol_sma * 0.5  # –û–±—ä–µ–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ 50% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ (—É–ø—Ä–æ—â–µ–Ω–æ)
            
            # –£–ë–†–ê–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞ (ADX) - ML —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –≤—Å–µ—Ö —Å—Ç–∞–¥–∏—è—Ö —Ä—ã–Ω–∫–∞
            # adx = row.get("adx", np.nan)
            # adx_strong = np.isfinite(adx) and adx > 25
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            rsi = row.get("rsi", np.nan)
            macd = row.get("macd", np.nan)
            macd_signal = row.get("macd_signal", np.nan)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
            indicators_agree = True
            if prediction == 1:  # LONG —Å–∏–≥–Ω–∞–ª
                # –î–ª—è LONG: RSI –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω, MACD –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ —Å–∏–≥–Ω–∞–ª–∞ (—Å–º—è–≥—á–µ–Ω–æ)
                if np.isfinite(rsi) and rsi > 85:  # –ë—ã–ª 80
                    indicators_agree = False
                if np.isfinite(macd) and np.isfinite(macd_signal) and macd < macd_signal * 0.90:  # –ë—ã–ª 0.95
                    indicators_agree = False
            elif prediction == -1:  # SHORT —Å–∏–≥–Ω–∞–ª
                # –î–ª—è SHORT: RSI –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω, MACD –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∂–µ —Å–∏–≥–Ω–∞–ª–∞ (—Å–º—è–≥—á–µ–Ω–æ)
                if np.isfinite(rsi) and rsi < 15:  # –ë—ã–ª 20
                    indicators_agree = False
                if np.isfinite(macd) and np.isfinite(macd_signal) and macd > macd_signal * 1.10:  # –ë—ã–ª 1.05
                    indicators_agree = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (—Å–º—è–≥—á–µ–Ω–æ –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏)
            volume_confirmation = True
            if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0:
                volume_ratio = volume / vol_sma
                # –¢–æ–ª—å–∫–æ –¥–ª—è –û–ß–ï–ù–¨ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (>85%) –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º (–±—ã–ª 80%)
                if confidence > 0.85 and volume_ratio < 0.7: # –ë—ã–ª 0.8
                    volume_confirmation = False
            
            # === –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä—ã–Ω–∫–∞ ===
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            dynamic_threshold = self.confidence_threshold
            
            # –ú–Ø–ì–ö–ò–ï –§–ò–õ–¨–¢–†–´: –ü—Ä–∏–º–µ–Ω—è–µ–º –¢–û–õ–¨–ö–û –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∏–∂–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            # –ï—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –≤—ã—à–µ dynamic_threshold, –º—ã –¥–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏!
            if prediction != 0 and confidence < dynamic_threshold:
                if not indicators_agree:
                    return Signal(row.name, Action.HOLD, f"ml_–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã_–Ω–µ_—Å–æ–≥–ª–∞—Å–Ω—ã_{strength}_{confidence_pct}%", current_price)
                if not volume_confirmation:
                    return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)

            
            # –£–ë–†–ê–ù–û: –§–∏–ª—å—Ç—Ä –ø–æ —Å–∏–ª–µ —Ç—Ä–µ–Ω–¥–∞ (ADX) - ML —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –≤—Å–µ—Ö —Å—Ç–∞–¥–∏—è—Ö —Ä—ã–Ω–∫–∞
            # if prediction != 0 and confidence < 0.75 and not adx_strong:
            #     return Signal(row.name, Action.HOLD, f"ml_—Å–ª–∞–±—ã–π_—Ç—Ä–µ–Ω–¥_{strength}_{confidence_pct}%", current_price)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω–∞—Ö (RSI > 85 –∏–ª–∏ < 15),
            # —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—Å–º—è–≥—á–µ–Ω–æ —Å 80/20)
            if prediction != 0 and np.isfinite(rsi):
                if (prediction == 1 and rsi > 85) or (prediction == -1 and rsi < 15):
                    # –í —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω–∞—Ö —Ç—Ä–µ–±—É–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ 5% –≤—ã—à–µ (–±—ã–ª–æ 10%)
                    extreme_threshold = dynamic_threshold * 1.05
                    if confidence < extreme_threshold:
                        return Signal(row.name, Action.HOLD, f"ml_–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã_–Ω–µ_—Å–æ–≥–ª–∞—Å–Ω—ã_RSI_{int(rsi)}_{strength}_{confidence_pct}%", current_price)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ LONG, SHORT –∏–ª–∏ HOLD
            # –£–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ min_strength_threshold –≤—ã—à–µ, —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º confidence_threshold
            if prediction == 1:  # LONG
                # –°–º—è–≥—á–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–ª–∏–∑–∫–∞ –∫ –ø–æ—Ä–æ–≥—É (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 15%), –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                effective_threshold = max(dynamic_threshold * 0.85, self.min_strength_threshold)  # –ú–∏–Ω–∏–º—É–º 85% –æ—Ç –ø–æ—Ä–æ–≥–∞
                if confidence < effective_threshold:
                    # –ú–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ - HOLD
                    return Signal(row.name, Action.HOLD, f"ml_–Ω–µ_–ø—Ä–æ—Ö–æ–¥–∏—Ç_–ø–æ—Ä–æ–≥_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏_{strength}_{confidence_pct}%", current_price)
                
                # –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–∑–∏—Ü–∏—è –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                if self.stability_filter and has_position == Bias.SHORT:
                    stability_threshold = max(self.confidence_threshold * 0.85, 0.45)
                    if confidence < stability_threshold:
                        return Signal(row.name, Action.HOLD, f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%", current_price)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º (—Å–º—è–≥—á–µ–Ω–æ: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –æ–±—ä–µ–º –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω)
                if not volume_ok and confidence < dynamic_threshold * 1.2:
                    return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                # –°–∏–≥–Ω–∞–ª LONG
                reason = f"ml_LONG_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct:.2f}%_SL_{sl_pct:.2f}%"
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –¥–ª—è ML
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "LONG",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct, 2),
                    "sl_pct": round(sl_pct, 2),
                    "target_profit_margin_pct": profit_pct,
                    "leverage": leverage,
                    "volume": round(volume, 0) if np.isfinite(volume) else None,
                    "vol_sma": round(vol_sma, 0) if np.isfinite(vol_sma) else None,
                    "vol_ratio": round(volume / vol_sma, 2) if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else None,
                    "volume_ok": volume_ok,
                    "has_position": has_position.value if has_position else None,
                    "indicators": f"ML Confidence={confidence_pct}% ({strength}), Vol={volume:.0f}/{vol_sma:.0f} ({volume/vol_sma:.2f}x)" if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else f"ML Confidence={confidence_pct}% ({strength})"
                }
                return Signal(row.name, Action.LONG, reason, current_price, indicators_info=indicators_info)
            
            elif prediction == -1:  # SHORT
                # –°–º—è–≥—á–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–ª–∏–∑–∫–∞ –∫ –ø–æ—Ä–æ–≥—É (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 15%), –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                effective_threshold = max(dynamic_threshold * 0.85, self.min_strength_threshold)  # –ú–∏–Ω–∏–º—É–º 85% –æ—Ç –ø–æ—Ä–æ–≥–∞
                if confidence < effective_threshold:
                    # –ú–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ - HOLD
                    return Signal(row.name, Action.HOLD, f"ml_–Ω–µ_–ø—Ä–æ—Ö–æ–¥–∏—Ç_–ø–æ—Ä–æ–≥_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏_{strength}_{confidence_pct}%", current_price)
                
                # –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–∑–∏—Ü–∏—è –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                if self.stability_filter and has_position == Bias.LONG:
                    stability_threshold = max(self.confidence_threshold * 0.85, 0.45)
                    if confidence < stability_threshold:
                        return Signal(row.name, Action.HOLD, f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%", current_price)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º (—Å–º—è–≥—á–µ–Ω–æ: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –æ–±—ä–µ–º –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω)
                if not volume_ok and confidence < dynamic_threshold * 1.2:
                    return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                # –°–∏–≥–Ω–∞–ª SHORT
                reason = f"ml_SHORT_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct:.2f}%_SL_{sl_pct:.2f}%"
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –¥–ª—è ML
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "SHORT",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct, 2),
                    "sl_pct": round(sl_pct, 2),
                    "target_profit_margin_pct": profit_pct,
                    "leverage": leverage,
                    "volume": round(volume, 0) if np.isfinite(volume) else None,
                    "vol_sma": round(vol_sma, 0) if np.isfinite(vol_sma) else None,
                    "vol_ratio": round(volume / vol_sma, 2) if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else None,
                    "volume_ok": volume_ok,
                    "has_position": has_position.value if has_position else None,
                    "indicators": f"ML Confidence={confidence_pct}% ({strength}), Vol={volume:.0f}/{vol_sma:.0f} ({volume/vol_sma:.2f}x)" if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else f"ML Confidence={confidence_pct}% ({strength})"
                }
                return Signal(row.name, Action.SHORT, reason, current_price, indicators_info=indicators_info)
            
            else:  # prediction == 0 (HOLD)
                # –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                reason = f"ml_–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ_—Å–∏–ª–∞_{strength}_{confidence_pct}%_–æ–∂–∏–¥–∞–Ω–∏–µ"
                return Signal(row.name, Action.HOLD, reason, current_price)
        
        except Exception as e:
            print(f"[ml_strategy] Error generating signal: {e}")
            return Signal(row.name, Action.HOLD, f"ml_–æ—à–∏–±–∫–∞_{str(e)[:20]}", current_price)


def build_ml_signals(
    df: pd.DataFrame,
    model_path: str,
    confidence_threshold: float = 0.5,
    min_signal_strength: str = "—Å–ª–∞–±–æ–µ",
    stability_filter: bool = True,
    leverage: int = 10,
    target_profit_pct_margin: float = 25.0,
    max_loss_pct_margin: float = 10.0,
) -> list[Signal]:
    """
    –°—Ç—Ä–æ–∏—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame.
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å OHLCV –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
        model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ ("—Å–ª–∞–±–æ–µ", "—É–º–µ—Ä–µ–Ω–Ω–æ–µ", "—Å—Ä–µ–¥–Ω–µ–µ", "—Å–∏–ª—å–Ω–æ–µ", "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ")
        stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    
    Returns:
        –°–ø–∏—Å–æ–∫ Signal –æ–±—ä–µ–∫—Ç–æ–≤
    """
    strategy = MLStrategy(model_path, confidence_threshold, min_signal_strength, stability_filter)
    signals: list[Signal] = []
    position_bias: Optional[Bias] = None
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ DataFrame –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    df_work = df.copy()
    
    # –ï—Å–ª–∏ timestamp –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å
    if "timestamp" in df_work.columns:
        df_work = df_work.set_index("timestamp")
    elif not isinstance(df_work.index, pd.DatetimeIndex):
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å –≤ DatetimeIndex
        try:
            df_work.index = pd.to_datetime(df_work.index)
        except:
            pass
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ OHLCV
    required_cols = ["open", "high", "low", "close", "volume"]
    if not all(col in df_work.columns for col in required_cols):
        print(f"[ml_strategy] Warning: Missing required columns. Available: {df_work.columns.tolist()}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–∏–≥–Ω–∞–ª—ã
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), Action.HOLD, "ml_missing_data", 0.0) 
                for i in range(len(df_work))]
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏—á–∏ –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ–≥–æ DataFrame –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ä–∞
    # –≠—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É, —Ç–∞–∫ –∫–∞–∫ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ - —Å–∞–º–∞—è –∑–∞—Ç—Ä–∞—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π (–±–µ–∑ verbose –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
    try:
        df_with_features = strategy.feature_engineer.create_technical_indicators(df_work)
    except Exception as e:
        print(f"[ml_strategy] Error preparing features: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), Action.HOLD, f"ml_error_{str(e)[:20]}", 0.0) 
                for i in range(len(df_work))]
    
    for idx, row in df_with_features.iterrows():
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞ (—É–∂–µ —Å –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏)
            df_until_now = df_with_features.loc[:idx]
            
            # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 200 –±–∞—Ä–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (SMA200, –∏ —Ç.–¥.)
            if len(df_until_now) < 200:
                signals.append(Signal(idx, Action.HOLD, "ml_insufficient_data", row["close"]))
                continue
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ - –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∏—Ö
            signal = strategy.generate_signal(
                row=row,
                df=df_until_now,  # –£–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ñ–∏—á–∏
                has_position=position_bias,
                current_price=row["close"],
                leverage=leverage,
                target_profit_pct_margin=target_profit_pct_margin,
                max_loss_pct_margin=max_loss_pct_margin,
            )
            signals.append(signal)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–≥–Ω–∞–ª–∞
            if signal.action == Action.LONG:
                if position_bias is None or position_bias == Bias.SHORT:
                    position_bias = Bias.LONG
                # –ï—Å–ª–∏ —É–∂–µ LONG - –æ—Å—Ç–∞–µ–º—Å—è LONG
            elif signal.action == Action.SHORT:
                if position_bias is None or position_bias == Bias.LONG:
                    position_bias = Bias.SHORT
                # –ï—Å–ª–∏ —É–∂–µ SHORT - –æ—Å—Ç–∞–µ–º—Å—è SHORT
            # HOLD - –ø–æ–∑–∏—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å
        except Exception as e:
            print(f"[ml_strategy] Error processing row {idx}: {e}")
            import traceback
            traceback.print_exc()
            signals.append(Signal(idx, Action.HOLD, f"ml_error_{str(e)[:20]}", row.get("close", 0.0)))
    
    return signals

