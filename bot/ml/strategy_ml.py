"""
ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é ML-–º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.
"""
import warnings
import os

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è scikit-learn –î–û –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –ü–ï–†–í–û–ô
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'
os.environ['SKLEARN_WARNINGS'] = 'ignore'

# –§–∏–ª—å—Ç—Ä—É–µ–º –≤—Å–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è sklearn
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', module='sklearn')
warnings.filterwarnings('ignore', message='.*sklearn.*')
warnings.filterwarnings('ignore', message='.*parallel.*')
warnings.filterwarnings('ignore', message='.*delayed.*')
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.*')
warnings.filterwarnings('ignore', message='.*should be used with.*')
warnings.filterwarnings('ignore', message='.*propagate the scikit-learn configuration.*')
# –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.delayed.*')
# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è XGBoost –ø—Ä–æ pickle –∏ –≤–µ—Ä—Å–∏–∏
warnings.filterwarnings('ignore', message='.*loading a serialized model.*')
warnings.filterwarnings('ignore', message='.*XGBoost.*')
os.environ['XGB_SILENT'] = '1'
os.environ['PYTHONWARNINGS'] = 'ignore'

import pickle
from pathlib import Path
from typing import Optional, Dict, Any

import numpy as np
import pandas as pd

from bot.strategy import Action, Bias, Signal
from bot.ml.feature_engineering import FeatureEngineer
from bot.config import StrategyParams
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –∞–Ω—Å–∞–º–±–ª—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pickle
from bot.ml.model_trainer import PreTrainedVotingEnsemble, WeightedEnsemble, TripleEnsemble


class MLStrategy:
    """
    ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã.
    """
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.5, min_signal_strength: str = "—Å–ª–∞–±–æ–µ", stability_filter: bool = True, use_dynamic_threshold: bool = True, min_signals_per_day: int = 1, max_signals_per_day: int = 10):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—é.
        
        Args:
            model_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pkl —Ñ–∞–π–ª)
            confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏ (0-1)
            min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ ("—Å–ª–∞–±–æ–µ", "—É–º–µ—Ä–µ–Ω–Ω–æ–µ", "—Å—Ä–µ–¥–Ω–µ–µ", "—Å–∏–ª—å–Ω–æ–µ", "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ")
            stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            use_dynamic_threshold: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            min_signals_per_day: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Ö–æ—Ç—è –±—ã 1 —Å–∏–≥–Ω–∞–ª)
            max_signals_per_day: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∏–∑–±—ã—Ç–æ—á–Ω—É—é —Ç–æ—Ä–≥–æ–≤–ª—é)
        """
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.min_signal_strength = min_signal_strength
        self.stability_filter = stability_filter
        self.use_dynamic_threshold = use_dynamic_threshold
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞
        strength_thresholds = {
            "—Å–ª–∞–±–æ–µ": 0.0,
            "—É–º–µ—Ä–µ–Ω–Ω–æ–µ": 0.6,
            "—Å—Ä–µ–¥–Ω–µ–µ": 0.7,
            "—Å–∏–ª—å–Ω–æ–µ": 0.8,
            "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ": 0.9
        }
        self.min_strength_threshold = strength_thresholds.get(min_signal_strength, 0.6)
        
        # –ò—Å—Ç–æ—Ä–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
        self.confidence_history = []
        self.max_history_size = 100
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        # –•—Ä–∞–Ω–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–∏–≥–Ω–∞–ª–æ–≤: [(timestamp, action, confidence), ...]
        self.signal_history = []
        self.max_signal_history = 20  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–∏–≥–Ω–∞–ª–æ–≤
        self.min_bars_between_opposite_signals = 4  # –ú–∏–Ω–∏–º—É–º –±–∞—Ä–æ–≤ –º–µ–∂–¥—É –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
        self.min_confidence_difference = 0.15  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É LONG –∏ SHORT (15%)
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        # –•—Ä–∞–Ω–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –¥–∞—Ç–∞–º: {date_str: count}
        self.daily_signals_count = {}
        self.min_signals_per_day = min_signals_per_day
        self.max_signals_per_day = max_signals_per_day
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.model_data = self._load_model()
        self.model = self.model_data["model"]
        self.scaler = self.model_data["scaler"]
        self.feature_names = self.model_data["feature_names"]
        self.is_ensemble = self.model_data.get("metadata", {}).get("model_type", "").startswith("ensemble")
        
        # –ï—Å–ª–∏ —ç—Ç–æ QuadEnsemble, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º feature_names –≤ lstm_trainer
        if hasattr(self.model, 'lstm_trainer') and self.model.lstm_trainer is not None:
            # –ï—Å–ª–∏ feature_names –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ lstm_trainer, –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
            if not hasattr(self.model.lstm_trainer, 'feature_names') or self.model.lstm_trainer.feature_names is None:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ scaler (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π)
                if hasattr(self.model.lstm_trainer, 'scaler') and self.model.lstm_trainer.scaler is not None:
                    expected_features = self.model.lstm_trainer.scaler.n_features_in_ if hasattr(self.model.lstm_trainer.scaler, 'n_features_in_') else None
                    if expected_features and self.feature_names:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ expected_features —Ñ–∏—á–µ–π (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LSTM)
                        # LSTM –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä–≤—ã–µ N —Ñ–∏—á–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 50)
                        self.model.lstm_trainer.feature_names = self.feature_names[:expected_features]
                        if not hasattr(self, '_lstm_feature_names_restored'):
                            print(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features")
                            self._lstm_feature_names_restored = True
                    elif self.feature_names:
                        # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ scaler, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ feature_names
                        self.model.lstm_trainer.feature_names = self.feature_names
                        if not hasattr(self, '_lstm_feature_names_restored'):
                            print(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features (from all features)")
                            self._lstm_feature_names_restored = True
                elif self.feature_names:
                    # –ï—Å–ª–∏ scaler –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ feature_names
                    self.model.lstm_trainer.feature_names = self.feature_names
                    if not hasattr(self, '_lstm_feature_names_restored'):
                        print(f"[ml_strategy] Restored LSTM feature_names: {len(self.model.lstm_trainer.feature_names)} features (scaler unavailable)")
                        self._lstm_feature_names_restored = True
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º feature engineer
        self.feature_engineer = FeatureEngineer()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        model_filename = Path(model_path).name
        symbol_from_model = "UNKNOWN"
        if "_" in model_filename:
            parts = model_filename.replace(".pkl", "").split("_")
            # –§–æ—Ä–º–∞—Ç—ã:
            # - rf_ETHUSDT_15_15m.pkl -> ["rf","ETHUSDT","15","15m"]
            # - ensemble_BTCUSDT_15_mtf.pkl -> ["ensemble","BTCUSDT","15","mtf"]
            # - triple_ensemble_BTCUSDT_15_15m.pkl -> ["triple","ensemble","BTCUSDT","15","15m"]
            # - quad_ensemble_BTCUSDT_15_mtf.pkl -> ["quad","ensemble","BTCUSDT","15","mtf"]
            if len(parts) >= 3 and parts[0] in ("triple", "quad") and parts[1] == "ensemble":
                symbol_from_model = parts[2]
            elif len(parts) >= 2:
                symbol_from_model = parts[1]
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        model_metadata = self.model_data.get("metadata", {})
        model_type_str = model_metadata.get("model_type", "unknown")
        if "ensemble" in model_type_str.lower():
            self.is_ensemble = True
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –ª–æ–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ)
        if not hasattr(self, '_model_loaded_logged'):
            model_type = 'üéØ ENSEMBLE' if self.is_ensemble else 'Single'
            cv_acc = self.model_data.get("metrics", {}).get('cv_mean', 0) if self.is_ensemble else 0
            print(f"[ml] {symbol_from_model}: {model_type} (CV:{cv_acc:.3f}, conf:{confidence_threshold}, stab:{stability_filter})")
            self._model_loaded_logged = True
    
    def _load_model(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞."""
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        
        with open(self.model_path, "rb") as f:
            model_data = pickle.load(f)
        
        return model_data
    
    def prepare_features(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> np.ndarray:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ DataFrame –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∏—á–∏)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            –ú–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        # –ï—Å–ª–∏ —Ñ–∏—á–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã (skip_feature_creation=True), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
        if skip_feature_creation:
            df_with_features = df.copy()
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∑–∞–Ω–æ–≤–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ timestamp –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ (–Ω—É–∂–Ω–æ –¥–ª—è feature_engineer)
            df_work = df.copy()
            if "timestamp" in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                df_work = df_work.set_index("timestamp")
            elif "timestamp" not in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                if isinstance(df_work.index, pd.DatetimeIndex):
                    pass  # –£–∂–µ DatetimeIndex
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
                    df_work.index = pd.to_datetime(df_work.index, errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏—á–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            print(f"[ml_strategy] Preparing features: input DataFrame has {len(df_work)} rows")
            try:
                df_with_features = self.feature_engineer.create_technical_indicators(df_work)
                print(f"[ml_strategy] After create_technical_indicators: {len(df_with_features)} rows, {len(df_with_features.columns)} columns")
            except TypeError as e:
                if "'>' not supported" in str(e) or "NoneType" in str(e):
                    print(f"[ml_strategy] ‚ùå ERROR: Comparison with None detected in create_technical_indicators")
                    print(f"[ml_strategy]   Error: {e}")
                    print(f"[ml_strategy]   Checking for None values in DataFrame...")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ None –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
                    for col in ["open", "high", "low", "close", "volume", "atr", "atr_pct", "rsi"]:
                        if col in df_work.columns:
                            none_count = df_work[col].isna().sum() + (df_work[col] == None).sum()
                            if none_count > 0:
                                print(f"[ml_strategy]   Column '{col}' has {none_count} None/NaN values")
                    raise
                raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OHLCV)
        key_columns = ["open", "high", "low", "close", "volume"]
        if all(col in df_with_features.columns for col in key_columns):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            rows_before = len(df_with_features)
            df_with_features = df_with_features[df_with_features[key_columns].notna().any(axis=1)]
            rows_after = len(df_with_features)
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ò —ç—Ç–æ –Ω–µ skip_feature_creation (—á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ª–æ–≥–∏)
            if not skip_feature_creation and rows_before != rows_after:
                print(f"[ml_strategy] After filtering key columns: {rows_before} -> {rows_after} rows")
        else:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ skip_feature_creation
            if not skip_feature_creation:
                missing_key_cols = [col for col in key_columns if col not in df_with_features.columns]
                print(f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing key columns: {missing_key_cols}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        if len(df_with_features) == 0:
            print(f"[ml_strategy] ‚ùå ERROR: No rows after filtering key columns")
            print(f"[ml_strategy]   Input DataFrame shape: {df_work.shape}")
            print(f"[ml_strategy]   After create_technical_indicators shape: {df_with_features.shape if 'df_with_features' in locals() else 'N/A'}")
            raise ValueError("No data available after creating features (all rows contain NaN in key columns)")
        
        # –í–ê–ñ–ù–û: –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Ñ–∏—á–∞—Ö –Ω—É–ª—è–º–∏ –ü–ï–†–ï–î –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –≤—ã—á–∏—Å–ª–∏–ª–∏—Å—å
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞—Ö (–Ω–æ –Ω–µ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö)
        feature_columns = [col for col in df_with_features.columns if col not in key_columns]
        if feature_columns:
            df_with_features[feature_columns] = df_with_features[feature_columns].fillna(0)
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏) NaN
        df_with_features = df_with_features.dropna(how='all')
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if len(df_with_features) == 0:
            raise ValueError("No data available after creating features (all rows contain NaN)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∏—á–µ–π
        missing_features = [f for f in self.feature_names if f not in df_with_features.columns]
        if missing_features:
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏
            if not hasattr(self, "_missing_features_warned"):
                print(
                    f"[ml_strategy] ‚ö†Ô∏è WARNING: Missing {len(missing_features)} features: "
                    f"{missing_features[:10]}..."
                )
                print(
                    f"[ml_strategy]   Expected {len(self.feature_names)} features, "
                    f"got {len(df_with_features.columns)}"
                )
                self._missing_features_warned = True
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏ –Ω—É–ª—è–º–∏ –æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ DataFrame
            zeros_df = pd.DataFrame(
                0.0,
                index=df_with_features.index,
                columns=missing_features,
            )
            df_with_features = pd.concat([df_with_features, zeros_df], axis=1)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∏—á–∏ (–∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –Ω–µ –æ–∂–∏–¥–∞—é—Ç—Å—è –º–æ–¥–µ–ª—å—é)
        extra_features = [f for f in df_with_features.columns if f not in self.feature_names and f not in key_columns]
        # –£–±–∏—Ä–∞–µ–º –ª–æ–≥–∏ –æ –ª–∏—à–Ω–∏—Ö —Ñ–∏—á–∞—Ö - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è (–æ–Ω–∏ –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
        if extra_features:
            self._extra_features_warned = True  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, –Ω–æ –Ω–µ –ª–æ–≥–∏—Ä—É–µ–º
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        X = df_with_features[self.feature_names].values
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if len(X) == 0:
            raise ValueError("No data available after feature selection")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π —Å –º–æ–¥–µ–ª—å—é
        if X.shape[1] != len(self.feature_names):
            raise ValueError(f"Feature count mismatch: X has {X.shape[1]} features, but model expects {len(self.feature_names)}")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
        except ValueError as e:
            if "features" in str(e).lower() or "n_features" in str(e).lower():
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π
                scaler_expected = getattr(self.scaler, 'n_features_in_', None)
                if scaler_expected is None:
                    # –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è sklearn - –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ shape
                    try:
                        scaler_expected = self.scaler.mean_.shape[0] if hasattr(self.scaler, 'mean_') else None
                    except:
                        pass
                
                if scaler_expected and X.shape[1] != scaler_expected:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è)
                    if not hasattr(self, '_feature_mismatch_warned'):
                        self._feature_mismatch_warned = True
                    
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –±–æ–ª—å—à–µ —Ñ–∏—á–µ–π, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω—É–ª—è–º–∏
                    if X.shape[1] < scaler_expected:
                        missing_count = scaler_expected - X.shape[1]
                        if not hasattr(self, '_feature_adjustment_logged'):
                            self._feature_adjustment_logged = True
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                        zeros = np.zeros((X.shape[0], missing_count))
                        X = np.hstack([X, zeros])
                    # –ï—Å–ª–∏ scaler –æ–∂–∏–¥–∞–µ—Ç –º–µ–Ω—å—à–µ —Ñ–∏—á–µ–π, –æ–±—Ä–µ–∑–∞–µ–º
                    elif X.shape[1] > scaler_expected:
                        X = X[:, :scaler_expected]
                
                # –ü—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                try:
                    X_scaled = self.scaler.transform(X)
                except ValueError as e2:
                    print(f"[ml_strategy] ‚ùå ERROR: Still cannot transform after adjustment")
                    print(f"[ml_strategy]   Scaler expects: {scaler_expected} features")
                    print(f"[ml_strategy]   X has: {X.shape[1]} features")
                    raise ValueError(f"Feature count mismatch: Scaler expects {scaler_expected} features, but got {X.shape[1]}. "
                                   f"Please retrain the model with the current feature set.") from e2
            else:
                raise
        
        return X_scaled
    
    def prepare_features_with_df(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> tuple[np.ndarray, pd.DataFrame]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –∏–∑ DataFrame –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ –º–∞—Å—Å–∏–≤, —Ç–∞–∫ –∏ DataFrame —Å —Ñ–∏—á–∞–º–∏.
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (–º–æ–∂–µ—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ñ–∏—á–∏)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            (X_scaled, df_with_features) –≥–¥–µ:
            - X_scaled: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏
            - df_with_features: DataFrame —Å–æ –≤—Å–µ–º–∏ —Ñ–∏—á–∞–º–∏ (–¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ QuadEnsemble)
        """
        # –ï—Å–ª–∏ —Ñ–∏—á–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã (skip_feature_creation=True), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
        if skip_feature_creation:
            df_with_features = df.copy()
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∑–∞–Ω–æ–≤–æ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ timestamp –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ (–Ω—É–∂–Ω–æ –¥–ª—è feature_engineer)
            df_work = df.copy()
            if "timestamp" in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                df_work = df_work.set_index("timestamp")
            elif "timestamp" not in df_work.columns and not isinstance(df_work.index, pd.DatetimeIndex):
                # –ï—Å–ª–∏ –Ω–µ—Ç timestamp, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                if isinstance(df_work.index, pd.DatetimeIndex):
                    pass  # –£–∂–µ DatetimeIndex
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
                    df_work.index = pd.to_datetime(df_work.index, errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏—á–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            if not skip_feature_creation:
                print(f"[ml_strategy] Preparing features: input DataFrame has {len(df_work)} rows")
            try:
                df_with_features = self.feature_engineer.create_technical_indicators(df_work)
                if not skip_feature_creation:
                    print(f"[ml_strategy] After create_technical_indicators: {len(df_with_features)} rows, {len(df_with_features.columns)} columns")
            except TypeError as e:
                if "'>' not supported" in str(e) or "NoneType" in str(e):
                    print(f"[ml_strategy] ‚ùå ERROR: Comparison with None detected in create_technical_indicators")
                    print(f"[ml_strategy]   Error: {e}")
                    raise
                raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OHLCV)
        key_columns = ["open", "high", "low", "close", "volume"]
        if all(col in df_with_features.columns for col in key_columns):
            rows_before = len(df_with_features)
            df_with_features = df_with_features[df_with_features[key_columns].notna().any(axis=1)]
            rows_after = len(df_with_features)
        else:
            missing_key_cols = [col for col in key_columns if col not in df_with_features.columns]
            raise ValueError(f"Missing key columns: {missing_key_cols}")
        
        if len(df_with_features) == 0:
            raise ValueError("No data available after filtering key columns")
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Ñ–∏—á–∞—Ö
        feature_columns = [col for col in df_with_features.columns if col not in key_columns]
        if feature_columns:
            df_with_features[feature_columns] = df_with_features[feature_columns].ffill().bfill().fillna(0.0)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∏—á–µ–π
        missing_features = [f for f in self.feature_names if f not in df_with_features.columns]
        if missing_features:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏ –Ω—É–ª—è–º–∏
            zeros_df = pd.DataFrame(
                0.0,
                index=df_with_features.index,
                columns=missing_features,
            )
            df_with_features = pd.concat([df_with_features, zeros_df], axis=1)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        X = df_with_features[self.feature_names].values
        
        if len(X) == 0:
            raise ValueError("No data available after feature selection")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
        except ValueError as e:
            if "features" in str(e).lower() or "n_features" in str(e).lower():
                scaler_expected = getattr(self.scaler, 'n_features_in_', None)
                if scaler_expected is None:
                    try:
                        scaler_expected = self.scaler.mean_.shape[0] if hasattr(self.scaler, 'mean_') else None
                    except:
                        pass
                
                if scaler_expected and X.shape[1] != scaler_expected:
                    if X.shape[1] < scaler_expected:
                        missing_count = scaler_expected - X.shape[1]
                        zeros = np.zeros((X.shape[0], missing_count))
                        X = np.hstack([X, zeros])
                    elif X.shape[1] > scaler_expected:
                        X = X[:, :scaler_expected]
                    
                    X_scaled = self.scaler.transform(X)
                else:
                    raise
            else:
                raise
        
        return X_scaled, df_with_features
    
    def predict(self, df: pd.DataFrame, skip_feature_creation: bool = False) -> tuple[int, float]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–∞—Ä–∞.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (OHLCV, —Ñ–∏—á–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–ª–∏ —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç)
            skip_feature_creation: –ï—Å–ª–∏ True, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã)
        
        Returns:
            (prediction, confidence) –≥–¥–µ:
            - prediction: 1 (LONG), -1 (SHORT), 0 (HOLD)
            - confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0-1)
        """
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ä
        if len(df) == 0:
            return 0, 0.0
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏ (—Å–æ–∑–¥–∞—Å—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ)
            # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏ X (–º–∞—Å—Å–∏–≤ —Ñ–∏—á–µ–π) –∏ df_with_features (DataFrame —Å —Ñ–∏—á–∞–º–∏) –¥–ª—è QuadEnsemble
            X, df_with_features = self.prepare_features_with_df(df, skip_feature_creation=skip_feature_creation)
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–∑–µ—Ü
            X_last = X[-1:].reshape(1, -1)
        except Exception as e:
            print(f"[ml_strategy] Error preparing features: {e}")
            return 0, 0.0
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if hasattr(self.model, "predict_proba"):
            # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (–≤–∫–ª—é—á–∞—è –∞–Ω—Å–∞–º–±–ª—å)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ QuadEnsemble (—Ç—Ä–µ–±—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è LSTM)
            if hasattr(self.model, 'lstm_trainer') and hasattr(self.model, 'sequence_length'):
                # QuadEnsemble: –ø–µ—Ä–µ–¥–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LSTM
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º df_with_features, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ñ–∏—á–∏
                proba = self.model.predict_proba(X_last, df_history=df_with_features)[0]
            else:
                # –û–±—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω—Å–∞–º–±–ª–∏ (TripleEnsemble, etc.)
                proba = self.model.predict_proba(X_last)[0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º proba –Ω–∞ NaN
            if np.any(np.isnan(proba)) or not np.all(np.isfinite(proba)):
                # –ï—Å–ª–∏ proba —Å–æ–¥–µ—Ä–∂–∏—Ç NaN, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                proba = np.array([0.33, 0.34, 0.33])  # SHORT, HOLD, LONG
                print(f"[ml_strategy] Warning: proba contains NaN, using uniform distribution")
            
            # –î–ª—è –∞–Ω—Å–∞–º–±–ª—è proba —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
            # –î–ª—è XGBoost –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–∑ [0, 1, 2]
            if self.is_ensemble:
                # –ê–Ω—Å–∞–º–±–ª—å —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [-1, 0, 1]
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if np.isnan(long_prob) or not np.isfinite(long_prob):
                    long_prob = 0.0
                if np.isnan(short_prob) or not np.isfinite(short_prob):
                    short_prob = 0.0
                if np.isnan(hold_prob) or not np.isfinite(hold_prob):
                    hold_prob = 0.0
                
                # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø –ê–ù–°–ê–ú–ë–õ–ï–ô: –¢—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É LONG/SHORT
                # –ü–æ–≤—ã—à–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π (–±—ã–ª–æ 0.1%, —Ç–µ–ø–µ—Ä—å 0.3%)
                ensemble_absolute_min = 0.003  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0.3% (–ø–æ–≤—ã—à–µ–Ω–æ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–ª–∞–±—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤)
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É LONG –∏ SHORT
                prob_diff = abs(long_prob - short_prob)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –≤—ã–±–∏—Ä–∞–µ–º LONG –∏–ª–∏ SHORT —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
                # 1. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—à–µ –º–∏–Ω–∏–º—É–º–∞
                # 2. –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É LONG –∏ SHORT –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ (–º–∏–Ω–∏–º—É–º min_confidence_difference)
                # 3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–π
                if long_prob >= ensemble_absolute_min and long_prob > short_prob and prob_diff >= self.min_confidence_difference:
                    # LONG –≤—ã—à–µ SHORT, –≤—ã—à–µ –º–∏–Ω–∏–º—É–º–∞ –∏ —Ä–∞–∑–Ω–∏—Ü–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ - –ø—Ä–∏–Ω–∏–º–∞–µ–º LONG
                    prediction = 1  # LONG
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                    # –ß–µ–º –±–æ–ª—å—à–µ —Ä–∞–∑–Ω–∏—Ü–∞, —Ç–µ–º –≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–æ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ–º long_prob)
                    confidence = min(long_prob * (1 + prob_diff * 0.3), long_prob)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ NaN
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = long_prob
                elif short_prob >= ensemble_absolute_min and short_prob > long_prob and prob_diff >= self.min_confidence_difference:
                    # SHORT –≤—ã—à–µ LONG, –≤—ã—à–µ –º–∏–Ω–∏–º—É–º–∞ –∏ —Ä–∞–∑–Ω–∏—Ü–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ - –ø—Ä–∏–Ω–∏–º–∞–µ–º SHORT
                    prediction = -1  # SHORT
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å SHORT, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                    confidence = min(short_prob * (1 + prob_diff * 0.3), short_prob)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ NaN
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = short_prob
                else:
                    # HOLD - –ª–∏–±–æ LONG –∏ SHORT –Ω–∏–∂–µ –º–∏–Ω–∏–º—É–º–∞, –ª–∏–±–æ —Ä–∞–∑–Ω–∏—Ü–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞
                    prediction = 0
                    confidence = hold_prob
                
                # Fallback: –µ—Å–ª–∏ –ª–æ–≥–∏–∫–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é
                # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ prediction –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ 0 (HOLD)
                # –ï—Å–ª–∏ prediction —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (LONG –∏–ª–∏ SHORT), –Ω–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–≥–æ
                if prediction == 0:
                    prediction_idx = np.argmax(proba)
                    prediction = prediction_idx - 1  # 0->-1, 1->0, 2->1
                    confidence = proba[prediction_idx]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                    if np.isnan(confidence) or not np.isfinite(confidence):
                        confidence = hold_prob if np.isfinite(hold_prob) else 0.0
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ confidence –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                    if prediction == 1:  # LONG
                        confidence = min(confidence, long_prob)
                    elif prediction == -1:  # SHORT
                        confidence = min(confidence, short_prob)
                    else:  # HOLD
                        confidence = min(confidence, hold_prob)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            elif len(proba) == 3:
                # proba[0] = SHORT (-1), proba[1] = HOLD (0), proba[2] = LONG (1)
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1  # 0->-1, 1->0, 2->1
                confidence = proba[prediction_idx]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º confidence –Ω–∞ NaN
                if np.isnan(confidence) or not np.isfinite(confidence):
                    confidence = 0.0
                
                # –£–õ–£–ß–®–ï–ù–ò–ï: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç HOLD, –Ω–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞
                long_prob = proba[2] if len(proba) > 2 else 0.0
                short_prob = proba[0] if len(proba) > 0 else 0.0
                hold_prob = proba[1] if len(proba) > 1 else 0.0
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if np.isnan(long_prob) or not np.isfinite(long_prob):
                    long_prob = 0.0
                if np.isnan(short_prob) or not np.isfinite(short_prob):
                    short_prob = 0.0
                if np.isnan(hold_prob) or not np.isfinite(hold_prob):
                    hold_prob = 0.0
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if self.use_dynamic_threshold and len(self.confidence_history) > 10:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π
                    recent_confidence_median = np.median(self.confidence_history[-20:])
                    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –º–µ–¥–∏–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                    adaptive_threshold = max(self.min_strength_threshold, recent_confidence_median * 0.9)
                else:
                    adaptive_threshold = self.min_strength_threshold
                
                # –ï—Å–ª–∏ HOLD –∏–º–µ–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, –Ω–æ LONG –∏–ª–∏ SHORT –∏–º–µ—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å,
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ (–µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–µ–≤—ã—à–∞—é—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥)
                if prediction == 0:  # HOLD
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è HOLD
                    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å LONG –∏–ª–∏ SHORT >= adaptive_threshold, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º HOLD
                    if long_prob >= adaptive_threshold and long_prob > short_prob:
                        prediction = 1  # LONG
                        confidence = long_prob
                    elif short_prob >= adaptive_threshold and short_prob > long_prob:
                        prediction = -1  # SHORT
                        confidence = short_prob
                    # –ò–Ω–∞—á–µ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ HOLD
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if len(self.confidence_history) >= self.max_history_size:
                    self.confidence_history.pop(0)
                self.confidence_history.append(confidence)
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                prediction_idx = np.argmax(proba)
                prediction = prediction_idx - 1 if len(proba) == 3 else prediction_idx
                confidence = proba[prediction_idx]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if np.isnan(prediction) or not np.isfinite(prediction):
                    prediction = 0
                if np.isnan(confidence) or not np.isfinite(confidence):
                    confidence = 0.0
        else:
            # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ predict_proba
            prediction_raw = self.model.predict(X_last)[0]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –ø–µ—Ä–µ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º
            if np.isnan(prediction_raw) or not np.isfinite(prediction_raw):
                prediction = 0  # HOLD –µ—Å–ª–∏ prediction_raw NaN
            else:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç -1, 0, 1 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if hasattr(self.model, 'classes_'):
                    # –ï—Å–ª–∏ –µ—Å—Ç—å classes_, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –∑–Ω–∞—á–µ–Ω–∏–µ
                    classes = self.model.classes_
                    if len(classes) == 3:
                        prediction = int(prediction_raw) - 1  # 0->-1, 1->0, 2->1
                    else:
                        prediction = int(prediction_raw)
                else:
                    prediction = int(prediction_raw)
            confidence = 1.0  # –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
        if np.isnan(prediction) or not np.isfinite(prediction):
            prediction = 0  # HOLD –µ—Å–ª–∏ prediction NaN
        if np.isnan(confidence) or not np.isfinite(confidence):
            confidence = 0.0  # –ù—É–ª–µ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –µ—Å–ª–∏ confidence NaN
        
        return int(prediction), float(confidence)
    
    def generate_signal(
        self,
        row: pd.Series,
        df: pd.DataFrame,
        has_position: Optional[Bias],
        current_price: float,
        leverage: int = 10,
        target_profit_pct_margin: float = 25.0,
        max_loss_pct_margin: float = 10.0,
    ) -> Signal:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
        
        Args:
            row: –¢–µ–∫—É—â–∏–π –±–∞—Ä (pd.Series)
            df: DataFrame —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏—á–µ–π)
            has_position: –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è (None, Bias.LONG, Bias.SHORT)
            current_price: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            leverage: –ü–ª–µ—á–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ TP/SL
            target_profit_pct_margin: –¶–µ–ª–µ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ –≤ % (20-30%)
            max_loss_pct_margin: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫ –æ—Ç –º–∞—Ä–∂–∏ –≤ %
        
        Returns:
            Signal –æ–±—ä–µ–∫—Ç
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª –∏–∑ model_path –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
            symbol = getattr(self, '_symbol', None)
            if symbol is None:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª –∏–∑ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏
                model_filename = Path(self.model_path).name
                if "_" in model_filename:
                    parts = model_filename.replace(".pkl", "").split("_")
                    if len(parts) >= 3 and parts[0] in ("triple", "quad") and parts[1] == "ensemble":
                        symbol = parts[2].upper()
                        self._symbol = symbol
                    elif len(parts) >= 2:
                        symbol = parts[1].upper()  # –ù–∞–ø—Ä–∏–º–µ—Ä, rf_ETHUSDT_15.pkl -> ETHUSDT
                        self._symbol = symbol
                    else:
                        symbol = "UNKNOWN"
                else:
                    symbol = "UNKNOWN"
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            is_volatile_symbol = symbol in ("ETHUSDT", "SOLUSDT")
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á–µ–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã –≤ build_ml_signals)
            prediction, confidence = self.predict(df, skip_feature_creation=True)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º TP/SL –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç —Ü–µ–Ω—ã –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏ –æ—Ç –º–∞—Ä–∂–∏
            # –ï—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å –æ—Ç –º–∞—Ä–∂–∏ = 25%, –∞ –ø–ª–µ—á–æ = 10x, —Ç–æ TP = 25% / 10 = 2.5%
            tp_pct = target_profit_pct_margin / leverage
            sl_pct = max_loss_pct_margin / leverage
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if confidence >= 0.9:
                strength = "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.8:
                strength = "—Å–∏–ª—å–Ω–æ–µ"
            elif confidence >= 0.7:
                strength = "—Å—Ä–µ–¥–Ω–µ–µ"
            elif confidence >= 0.6:
                strength = "—É–º–µ—Ä–µ–Ω–Ω–æ–µ"
            else:
                strength = "—Å–ª–∞–±–æ–µ"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω—É—é –ø—Ä–∏—á–∏–Ω—É
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –ø–µ—Ä–µ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º
            if np.isnan(confidence) or not np.isfinite(confidence):
                confidence = 0.0
            confidence_pct = int(confidence * 100) if np.isfinite(confidence) else 0
            profit_pct = int(target_profit_pct_margin)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
            from datetime import datetime, timezone
            current_date = datetime.now(timezone.utc).date()
            date_str = current_date.isoformat()
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∏ —Ä–∞–±–æ—Ç—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
            signals_today = self.daily_signals_count.get(date_str, 0)
            
            # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –∂–µ—Å—Ç–∫–∏–º –ª–∏–º–∏—Ç–æ–º
            # –¶–µ–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞—Ç—å 1-10 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
            # –ú–∞–∫—Å–∏–º—É–º —Å–∏–≥–Ω–∞–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∫ –∑–∞—â–∏—Ç–∞ –æ—Ç –æ—à–∏–±–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 100+ —Å–∏–≥–Ω–∞–ª–æ–≤)
            if prediction != 0 and signals_today >= 100:  # –¢–æ–ª—å–∫–æ –∑–∞—â–∏—Ç–∞ –æ—Ç –æ—à–∏–±–æ–∫ (100+ —Å–∏–≥–Ω–∞–ª–æ–≤ - —è–≤–Ω–∞—è –æ—à–∏–±–∫–∞)
                return Signal(row.name, Action.HOLD, f"ml_–∑–∞—â–∏—Ç–∞_–æ—Ç_–æ—à–∏–±–æ–∫_—Å–ª–∏—à–∫–æ–º_–º–Ω–æ–≥–æ_—Å–∏–≥–Ω–∞–ª–æ–≤_{signals_today}", current_price)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å–∏–ª—É —Å–∏–≥–Ω–∞–ª–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è LONG/SHORT, –Ω–µ –¥–ª—è HOLD)
            # –ü–æ—Ä–æ–≥–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã —Ç–∞–∫, —á—Ç–æ–±—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞—Ç—å 1-10 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å
            if self.is_ensemble:
                # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–Ω–∏–∂–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
                # –¶–µ–ª—å: 1-10 —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–±—Ä–∞–∑–æ–º
                if is_volatile_symbol:
                    min_strength = 0.003  # 0.3% –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 0.5%)
                else:
                    min_strength = 0.004  # 0.4% –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 0.7%)
            else:
                # –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
                if is_volatile_symbol:
                    min_strength = self.min_strength_threshold * 0.3
                else:
                    min_strength = self.min_strength_threshold
            
            if prediction != 0 and confidence < min_strength:
                # –°–∏–≥–Ω–∞–ª –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å–∏–ª—ã - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º HOLD
                return Signal(row.name, Action.HOLD, f"ml_—Å–∏–ª–∞_—Å–ª–∏—à–∫–æ–º_—Å–ª–∞–±–∞—è_{strength}_{confidence_pct}%_–º–∏–Ω_{int(min_strength*100)}%", current_price)
            
            # –ù–û–í–´–ô –§–ò–õ–¨–¢–†: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            if prediction != 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                opposite_action = Action.SHORT if prediction == 1 else Action.LONG
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –∫–æ–Ω—Ü–∞ —Å–ø–∏—Å–∫–∞
                recent_opposite_count = 0
                for i in range(min(self.min_bars_between_opposite_signals, len(self.signal_history))):
                    idx = len(self.signal_history) - 1 - i
                    if idx >= 0:
                        sig = self.signal_history[idx]
                        if sig[1] == opposite_action:
                            recent_opposite_count += 1
                
                if recent_opposite_count > 0:
                    # –ë—ã–ª –Ω–µ–¥–∞–≤–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–π —Å–∏–≥–Ω–∞–ª - —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–±—É–µ–º—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ 30-50% –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                    stability_multiplier = 1.3 if is_volatile_symbol else 1.5
                    required_confidence = min_strength * stability_multiplier
                    
                    if confidence < required_confidence:
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–π_—Å–∏–≥–Ω–∞–ª_{strength}_{confidence_pct}%_—Ç—Ä–µ–±—É–µ—Ç—Å—è_{int(required_confidence*100)}%_–ø–æ—Å–ª–µ_{opposite_action.value}", 
                            current_price
                        )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –Ω–µ–¥–∞–≤–Ω–æ —Ç–∞–∫–æ–π –∂–µ —Å–∏–≥–Ω–∞–ª (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
                same_action = Action.LONG if prediction == 1 else Action.SHORT
                recent_same_count = 0
                for i in range(min(2, len(self.signal_history))):
                    idx = len(self.signal_history) - 1 - i
                    if idx >= 0:
                        sig = self.signal_history[idx]
                        if sig[1] == same_action:
                            recent_same_count += 1
                
                if recent_same_count > 0:
                    # –ë—ã–ª –Ω–µ–¥–∞–≤–Ω–æ —Ç–∞–∫–æ–π –∂–µ —Å–∏–≥–Ω–∞–ª - —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤—Ö–æ–¥–∞
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–±—É–µ–º—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ 20% –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤—Ö–æ–¥–∞
                    repeat_multiplier = 1.2
                    required_confidence = min_strength * repeat_multiplier
                    
                    if confidence < required_confidence:
                        return Signal(
                            row.name, 
                            Action.HOLD, 
                            f"ml_–¥—É–±–ª–∏—Ä—É—é—â–∏–π_—Å–∏–≥–Ω–∞–ª_{strength}_{confidence_pct}%_—Ç—Ä–µ–±—É–µ—Ç—Å—è_{int(required_confidence*100)}%", 
                            current_price
                        )
            
            # === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ===
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            volume = row.get("volume", np.nan)
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å vol_sma –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            # –í –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ prepare_with_indicators –µ—Å—Ç—å vol_sma
            # –í –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ FeatureEngineer –µ—Å—Ç—å volume_sma_20
            vol_sma = row.get("vol_sma", np.nan)
            if not np.isfinite(vol_sma):
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º volume_sma_20 –∏–∑ —Ñ–∏—á–µ–π FeatureEngineer
                vol_sma = row.get("volume_sma_20", np.nan)
            if not np.isfinite(vol_sma):
                # –ï—Å–ª–∏ vol_sma –≤—Å–µ –µ—â–µ –Ω–µ—Ç, –≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Å—Ç—É—é SMA –∑–∞ 20 –ø–µ—Ä–∏–æ–¥–æ–≤ –∏–∑ df
                try:
                    if len(df) >= 20:
                        vol_sma = df["volume"].rolling(window=20).mean().iloc[-1]
                except:
                    pass
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞: –µ—Å–ª–∏ vol_sma –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Å—á–∏—Ç–∞–µ–º –æ–±—ä–µ–º OK
            # –ï—Å–ª–∏ vol_sma –¥–æ—Å—Ç—É–ø–µ–Ω, —Ç—Ä–µ–±—É–µ–º —Ç–æ–ª—å–∫–æ 50% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ (–≤–º–µ—Å—Ç–æ 80%)
            if not np.isfinite(vol_sma):
                volume_ok = True  # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ä–µ–¥–Ω–µ–º –æ–±—ä–µ–º–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª
            else:
                volume_ok = np.isfinite(volume) and volume > vol_sma * 0.5  # –û–±—ä–µ–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ 50% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ (—É–ø—Ä–æ—â–µ–Ω–æ)
            
            # === –ù–û–í–´–ï –§–ò–õ–¨–¢–†–´: –£–ª—É—á—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫ ML-—Ç—Ä–µ–π–¥–∏–Ω–≥–∞ ===
            
            # 1. –§–∏–ª—å—Ç—Ä –ø–æ —Ç—Ä–µ–Ω–¥—É (MA): –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–æ–π MA
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—É—é MA (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: SMA50 > EMA50 > SMA20 > EMA20)
            sma_20 = row.get("sma_20", np.nan)
            sma_50 = row.get("sma_50", np.nan)
            sma = row.get("sma", np.nan)  # SMA20 –∏–∑ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            ema_20 = row.get("ema_20", np.nan)
            ema_50 = row.get("ema_50", np.nan)
            
            # –í—ã—á–∏—Å–ª—è–µ–º SMA50/EMA50 –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã
            if not np.isfinite(sma_50):
                try:
                    if len(df) >= 50:
                        sma_50 = df["close"].rolling(window=50).mean().iloc[-1]
                except:
                    pass
            
            if not np.isfinite(ema_50):
                try:
                    if len(df) >= 50:
                        ema_50 = df["close"].ewm(span=50, adjust=False).mean().iloc[-1]
                except:
                    pass
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é MA –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ —Ç—Ä–µ–Ω–¥–∞
            trend_ma = None
            ma_type = None  # –¢–∏–ø MA: "sma50", "ema50", "sma20", "ema20"
            if np.isfinite(sma_50):
                trend_ma = sma_50
                ma_type = "sma50"
            elif np.isfinite(ema_50):
                trend_ma = ema_50
                ma_type = "ema50"
            elif np.isfinite(sma) or np.isfinite(sma_20):
                trend_ma = sma if np.isfinite(sma) else sma_20
                ma_type = "sma20"
            elif np.isfinite(ema_20):
                trend_ma = ema_20
                ma_type = "ema20"
            
            trend_filter_ok = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if prediction != 0 and trend_ma is not None and np.isfinite(trend_ma):
                price = row.get("close", current_price)
                # –î–ª—è LONG: —Ü–µ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—à–µ MA (–∏–ª–∏ –±–ª–∏–∑–∫–æ –∫ –Ω–µ–π, –¥–æ–ø—É—Å–∫ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ MA)
                # –î–ª—è SMA –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –¥–æ–ø—É—Å–∫ (0.5%), –¥–ª—è EMA - –±–æ–ª–µ–µ –º—è–≥–∫–∏–π (0.3%)
                ma_tolerance = 0.003 if ma_type in ("ema50", "ema20") else 0.005
                
                if prediction == 1:  # LONG —Å–∏–≥–Ω–∞–ª
                    if price < trend_ma * (1 - ma_tolerance):  # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–∏–∂–µ MA –±–æ–ª–µ–µ —á–µ–º –Ω–∞ –¥–æ–ø—É—Å–∫
                        # –¢—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –≤—Ö–æ–¥–∞ –ø—Ä–æ—Ç–∏–≤ —Ç—Ä–µ–Ω–¥–∞
                        # –î–ª—è ETHUSDT –∏ SOLUSDT –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ (–æ–Ω–∏ –±–æ–ª–µ–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã)
                        if is_volatile_symbol:
                            threshold_multiplier = 1.05 if confidence < 0.5 else 1.08
                        else:
                            threshold_multiplier = 1.12 if confidence < 0.5 else 1.15
                        if confidence < self.confidence_threshold * threshold_multiplier:
                            trend_filter_ok = False
                elif prediction == -1:  # SHORT —Å–∏–≥–Ω–∞–ª
                    if price > trend_ma * (1 + ma_tolerance):  # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –≤—ã—à–µ MA –±–æ–ª–µ–µ —á–µ–º –Ω–∞ –¥–æ–ø—É—Å–∫
                        if is_volatile_symbol:
                            threshold_multiplier = 1.05 if confidence < 0.5 else 1.08
                        else:
                            threshold_multiplier = 1.12 if confidence < 0.5 else 1.15
                        if confidence < self.confidence_threshold * threshold_multiplier:
                            trend_filter_ok = False
            
            # 2. –§–∏–ª—å—Ç—Ä –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: –Ω–µ –≤—Ö–æ–¥–∏—Ç—å –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            atr = row.get("atr", np.nan)
            atr_pct = row.get("atr_pct", np.nan)
            if not np.isfinite(atr_pct):
                # –í—ã—á–∏—Å–ª—è–µ–º ATR% –∏–∑ ATR –∏ —Ü–µ–Ω—ã
                if np.isfinite(atr) and current_price > 0:
                    atr_pct = (atr / current_price) * 100
            
            volatility_ok = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if np.isfinite(atr_pct):
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏–º–≤–æ–ª–∞
                # ETHUSDT –∏ SOLUSDT –æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã, —á–µ–º BTCUSDT
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –Ω–∏—Ö
                if is_volatile_symbol:
                    volatility_threshold = 0.20  # –ï—â–µ –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    threshold_multiplier = 1.05  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                else:
                    volatility_threshold = 0.25  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (0.25% –≤–º–µ—Å—Ç–æ 0.3%)
                    threshold_multiplier = 1.08  # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (+8% –≤–º–µ—Å—Ç–æ +10%)
                
                # –ï—Å–ª–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è, —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                if atr_pct < volatility_threshold and confidence < self.confidence_threshold * threshold_multiplier:
                    volatility_ok = False
            
            # 3. –§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ä—ã–Ω–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º Higher Highs / Higher Lows –¥–ª—è LONG, Lower Highs / Lower Lows –¥–ª—è SHORT
            structure_ok = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            try:
                if len(df) >= 20:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–∫–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π —Ä–µ–∞–∫—Ü–∏–∏ (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è ETHUSDT –∏ SOLUSDT)
                    window_size = 8  # –ë—ã–ª–æ 10, —Ç–µ–ø–µ—Ä—å 8 –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π —Ä–µ–∞–∫—Ü–∏–∏
                    lookback = 4  # –ë—ã–ª–æ 5, —Ç–µ–ø–µ—Ä—å 4
                    
                    recent_highs = df["high"].rolling(window=window_size).max().iloc[-lookback:].values
                    recent_lows = df["low"].rolling(window=window_size).min().iloc[-lookback:].values
                    
                    if prediction == 1:  # LONG
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–∞–∫—Å–∏–º—É–º—ã —Ä–∞—Å—Ç—É—Ç (Higher Highs)
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –¥–æ–ø—É—Å–∫ –¥–ª—è ETHUSDT –∏ SOLUSDT
                        tolerance = 0.0010 if is_volatile_symbol else 0.0015
                        if len(recent_highs) >= 2:
                            if recent_highs[-1] < recent_highs[-2] * (1 - tolerance):
                                # –¢—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                                if is_volatile_symbol:
                                    threshold_multiplier = 1.05 if confidence < 0.5 else 1.08
                                else:
                                    threshold_multiplier = 1.08 if confidence < 0.5 else 1.1
                                if confidence < self.confidence_threshold * threshold_multiplier:
                                    structure_ok = False
                    elif prediction == -1:  # SHORT
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–∏–Ω–∏–º—É–º—ã –ø–∞–¥–∞—é—Ç (Lower Lows)
                        tolerance = 0.0010 if is_volatile_symbol else 0.0015
                        if len(recent_lows) >= 2:
                            if recent_lows[-1] > recent_lows[-2] * (1 + tolerance):
                                if is_volatile_symbol:
                                    threshold_multiplier = 1.05 if confidence < 0.5 else 1.08
                                else:
                                    threshold_multiplier = 1.08 if confidence < 0.5 else 1.1
                                if confidence < self.confidence_threshold * threshold_multiplier:
                                    structure_ok = False
            except:
                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä
            
            # 4. –§–∏–ª—å—Ç—Ä –ø–æ —Å–∏–ª–µ —Ç—Ä–µ–Ω–¥–∞ (ADX): –¥–ª—è ETHUSDT –∏ SOLUSDT –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
            # –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –≤—Ö–æ–¥–æ–≤ –≤ —Å–ª–∞–±—ã–µ —Ç—Ä–µ–Ω–¥—ã, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é
            adx = row.get("adx", np.nan)
            adx_filter_ok = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if np.isfinite(adx) and prediction != 0:
                # –î–ª—è —Å–ª–∞–±—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (< 0.5 —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏) —Ç—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π ADX
                # –î–ª—è ETHUSDT –∏ SOLUSDT –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                if is_volatile_symbol:
                    min_adx = 18 if confidence < 0.5 else 15
                    adx_threshold_multiplier = 1.02
                else:
                    min_adx = 20 if confidence < 0.5 else 18
                    adx_threshold_multiplier = 1.05
                if adx < min_adx and confidence < self.confidence_threshold * adx_threshold_multiplier:
                    # –¢–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å —Å–ª–∞–±—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –±–ª–æ–∫–∏—Ä—É–µ–º –ø—Ä–∏ —Å–ª–∞–±–æ–º —Ç—Ä–µ–Ω–¥–µ
                    adx_filter_ok = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            rsi = row.get("rsi", np.nan)
            macd = row.get("macd", np.nan)
            macd_signal = row.get("macd_signal", np.nan)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
            indicators_agree = True
            if prediction == 1:  # LONG —Å–∏–≥–Ω–∞–ª
                # –î–ª—è LONG: RSI –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω, MACD –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ —Å–∏–≥–Ω–∞–ª–∞ (—Å–º—è–≥—á–µ–Ω–æ)
                if np.isfinite(rsi) and rsi > 85:  # –ë—ã–ª 80
                    indicators_agree = False
                if np.isfinite(macd) and np.isfinite(macd_signal) and macd < macd_signal * 0.90:  # –ë—ã–ª 0.95
                    indicators_agree = False
            elif prediction == -1:  # SHORT —Å–∏–≥–Ω–∞–ª
                # –î–ª—è SHORT: RSI –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω, MACD –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∂–µ —Å–∏–≥–Ω–∞–ª–∞ (—Å–º—è–≥—á–µ–Ω–æ)
                if np.isfinite(rsi) and rsi < 15:  # –ë—ã–ª 20
                    indicators_agree = False
                if np.isfinite(macd) and np.isfinite(macd_signal) and macd > macd_signal * 1.10:  # –ë—ã–ª 1.05
                    indicators_agree = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (—Å–º—è–≥—á–µ–Ω–æ –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏)
            volume_confirmation = True
            if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0:
                volume_ratio = volume / vol_sma
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –æ–±—ä–µ–º–∞: –¥–ª—è ETHUSDT –∏ SOLUSDT –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                # –¢–æ–ª—å–∫–æ –¥–ª—è –û–ß–ï–ù–¨ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (>85%) –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º
                if is_volatile_symbol:
                    min_volume_ratio = 0.5 if confidence < 0.5 else 0.6
                    volume_check_threshold = 0.90  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
                else:
                    min_volume_ratio = 0.6 if confidence < 0.5 else 0.7
                    volume_check_threshold = 0.85
                if confidence > volume_check_threshold and volume_ratio < min_volume_ratio:
                    volume_confirmation = False
            
            # === –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä—ã–Ω–∫–∞ ===
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            # –î–ª—è ETHUSDT –∏ SOLUSDT –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
            if is_volatile_symbol:
                dynamic_threshold = self.confidence_threshold * 0.75  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –Ω–∞ 25% –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            else:
                dynamic_threshold = self.confidence_threshold
            
            # –ú–Ø–ì–ö–ò–ï –§–ò–õ–¨–¢–†–´: –ü—Ä–∏–º–µ–Ω—è–µ–º –¢–û–õ–¨–ö–û –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∏–∂–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            # –ï—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –≤—ã—à–µ dynamic_threshold, –º—ã –¥–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏!
            # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –ø–æ—á—Ç–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            if prediction != 0 and confidence < dynamic_threshold:
                if self.is_ensemble:
                    # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –æ—Ç–∫–ª—é—á–∞–µ–º –ø–æ—á—Ç–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã - –¥–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
                    # –¢–æ–ª—å–∫–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (RSI > 95 –∏–ª–∏ < 5)
                    if np.isfinite(rsi):
                        extreme_rsi = (prediction == 1 and rsi > 95) or (prediction == -1 and rsi < 5)
                        if extreme_rsi:
                            rsi_int = int(rsi) if np.isfinite(rsi) else 0
                            return Signal(row.name, Action.HOLD, f"ml_—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π_RSI_{rsi_int}_{strength}_{confidence_pct}%", current_price)
                    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π
                elif is_volatile_symbol:
                    # –î–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ–º –¢–û–õ–¨–ö–û —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
                    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ RSI –≤ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –∑–æ–Ω–µ (>90 –∏–ª–∏ <10) –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è
                    if np.isfinite(rsi):
                        extreme_rsi = (prediction == 1 and rsi > 90) or (prediction == -1 and rsi < 10)
                        if extreme_rsi and confidence < dynamic_threshold * 0.5:
                            rsi_int = int(rsi) if np.isfinite(rsi) else 0
                            return Signal(row.name, Action.HOLD, f"ml_—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π_RSI_{rsi_int}_{strength}_{confidence_pct}%", current_price)
                    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                else:
                    # –î–ª—è BTCUSDT –ø—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã
                    if not indicators_agree:
                        return Signal(row.name, Action.HOLD, f"ml_–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã_–Ω–µ_—Å–æ–≥–ª–∞—Å–Ω—ã_{strength}_{confidence_pct}%", current_price)
                    if not volume_confirmation:
                        return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                    if not trend_filter_ok:
                        return Signal(row.name, Action.HOLD, f"ml_—Ç—Ä–µ–Ω–¥_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                    if not volatility_ok:
                        return Signal(row.name, Action.HOLD, f"ml_–Ω–∏–∑–∫–∞—è_–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å_{strength}_{confidence_pct}%", current_price)
                    if not structure_ok:
                        return Signal(row.name, Action.HOLD, f"ml_—Å—Ç—Ä—É–∫—Ç—É—Ä–∞_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                    if not adx_filter_ok:
                        adx_int = int(adx) if np.isfinite(adx) else 0
                        return Signal(row.name, Action.HOLD, f"ml_—Å–ª–∞–±—ã–π_—Ç—Ä–µ–Ω–¥_ADX_{adx_int}_{strength}_{confidence_pct}%", current_price)

            
            # –£–ë–†–ê–ù–û: –§–∏–ª—å—Ç—Ä –ø–æ —Å–∏–ª–µ —Ç—Ä–µ–Ω–¥–∞ (ADX) - ML —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –≤—Å–µ—Ö —Å—Ç–∞–¥–∏—è—Ö —Ä—ã–Ω–∫–∞
            # if prediction != 0 and confidence < 0.75 and not adx_strong:
            #     return Signal(row.name, Action.HOLD, f"ml_—Å–ª–∞–±—ã–π_—Ç—Ä–µ–Ω–¥_{strength}_{confidence_pct}%", current_price)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω–∞—Ö (RSI > 85 –∏–ª–∏ < 15),
            # —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –¥–ª—è BTCUSDT, –Ω–µ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π)
            if prediction != 0 and np.isfinite(rsi) and not is_volatile_symbol and not self.is_ensemble:
                if (prediction == 1 and rsi > 85) or (prediction == -1 and rsi < 15):
                    # –í —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–æ–Ω–∞—Ö —Ç—Ä–µ–±—É–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ 5% –≤—ã—à–µ (–±—ã–ª–æ 10%)
                    extreme_threshold = dynamic_threshold * 1.05
                    if confidence < extreme_threshold:
                        rsi_int = int(rsi) if np.isfinite(rsi) else 0
                        return Signal(row.name, Action.HOLD, f"ml_–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã_–Ω–µ_—Å–æ–≥–ª–∞—Å–Ω—ã_RSI_{rsi_int}_{strength}_{confidence_pct}%", current_price)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ LONG, SHORT –∏–ª–∏ HOLD
            # –£–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ min_strength_threshold –≤—ã—à–µ, —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º confidence_threshold
            if prediction == 1:  # LONG
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 1-10 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å
                if self.is_ensemble:
                    # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–Ω–∏–∂–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ (15-20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ) –¥–ª—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
                    # –¶–µ–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞—Ç—å 1-10 —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å
                    threshold_mult = 0.15 if is_volatile_symbol else 0.20  # 15-20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 25-35%)
                    # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π —Ç–∞–∫–∂–µ —Å–Ω–∏–∂–∞–µ–º dynamic_threshold
                    dynamic_threshold = self.confidence_threshold * 0.20  # 20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 30%)
                else:
                    # –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
                    threshold_mult = 0.70 if is_volatile_symbol else 0.85
                
                effective_threshold = max(dynamic_threshold * threshold_mult, min_strength)
                # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π effective_threshold —Ç–µ–ø–µ—Ä—å –≤—ã—à–µ, —á—Ç–æ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ª–∞–±—ã–µ —Å–∏–≥–Ω–∞–ª—ã
                if confidence < effective_threshold:
                    # –ú–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ - HOLD
                    return Signal(row.name, Action.HOLD, f"ml_–Ω–µ_–ø—Ä–æ—Ö–æ–¥–∏—Ç_–ø–æ—Ä–æ–≥_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏_{strength}_{confidence_pct}%_–º–∏–Ω_{int(effective_threshold*100)}%", current_price)
                
                # –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–∑–∏—Ü–∏—è –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —á–∞—Å—Ç–æ–π —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                if self.stability_filter and has_position == Bias.SHORT:
                    if self.is_ensemble:
                        stability_threshold = max(self.confidence_threshold * 0.40, 0.25)  # –ü–æ–≤—ã—à–µ–Ω–æ —Å 0.1% –¥–æ 25-40%
                    elif is_volatile_symbol:
                        stability_threshold = max(self.confidence_threshold * 0.70, 0.35)  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                    else:
                        stability_threshold = max(self.confidence_threshold * 0.85, 0.45)
                    if confidence < stability_threshold:
                        return Signal(row.name, Action.HOLD, f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%", current_price)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º (—Å–º—è–≥—á–µ–Ω–æ: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –æ–±—ä–µ–º –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω)
                # –î–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–µ–Ω–∞
                if not is_volatile_symbol:
                    volume_threshold_mult = 1.2
                    if not volume_ok and confidence < dynamic_threshold * volume_threshold_mult:
                        return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                # –°–∏–≥–Ω–∞–ª LONG
                reason = f"ml_LONG_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct:.2f}%_SL_{sl_pct:.2f}%"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤
                signal_action = Action.LONG
                self.signal_history.append((row.name, signal_action, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –¥–µ–Ω—å
                self.daily_signals_count[date_str] = signals_today + 1
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                from datetime import timedelta
                cutoff_date = (current_date - timedelta(days=7)).isoformat()
                self.daily_signals_count = {k: v for k, v in self.daily_signals_count.items() if k >= cutoff_date}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –¥–ª—è ML
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "LONG",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct, 2),
                    "sl_pct": round(sl_pct, 2),
                    "target_profit_margin_pct": profit_pct,
                    "leverage": leverage,
                    "volume": round(volume, 0) if np.isfinite(volume) else None,
                    "vol_sma": round(vol_sma, 0) if np.isfinite(vol_sma) else None,
                    "vol_ratio": round(volume / vol_sma, 2) if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else None,
                    "volume_ok": volume_ok,
                    "has_position": has_position.value if has_position else None,
                    "indicators": f"ML Confidence={confidence_pct}% ({strength}), Vol={volume:.0f}/{vol_sma:.0f} ({volume/vol_sma:.2f}x)" if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else f"ML Confidence={confidence_pct}% ({strength})"
                }
                return Signal(row.name, Action.LONG, reason, current_price, indicators_info=indicators_info)
            
            elif prediction == -1:  # SHORT
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 1-10 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å
                if self.is_ensemble:
                    # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–Ω–∏–∂–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ (15-20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ) –¥–ª—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
                    # –¶–µ–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∞—Ç—å 1-10 —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –¥–µ–Ω—å
                    threshold_mult = 0.15 if is_volatile_symbol else 0.20  # 15-20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 25-35%)
                    # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π —Ç–∞–∫–∂–µ —Å–Ω–∏–∂–∞–µ–º dynamic_threshold
                    dynamic_threshold = self.confidence_threshold * 0.20  # 20% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ (—Å–Ω–∏–∂–µ–Ω–æ: –±—ã–ª–æ 30%)
                else:
                    # –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
                    threshold_mult = 0.70 if is_volatile_symbol else 0.85
                
                effective_threshold = max(dynamic_threshold * threshold_mult, min_strength)
                # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π effective_threshold —Ç–µ–ø–µ—Ä—å –≤—ã—à–µ, —á—Ç–æ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ª–∞–±—ã–µ —Å–∏–≥–Ω–∞–ª—ã
                if confidence < effective_threshold:
                    # –ú–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ - HOLD
                    return Signal(row.name, Action.HOLD, f"ml_–Ω–µ_–ø—Ä–æ—Ö–æ–¥–∏—Ç_–ø–æ—Ä–æ–≥_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏_{strength}_{confidence_pct}%_–º–∏–Ω_{int(effective_threshold*100)}%", current_price)
                
                # –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–∑–∏—Ü–∏—è –≤ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —á–∞—Å—Ç–æ–π —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                if self.stability_filter and has_position == Bias.LONG:
                    if self.is_ensemble:
                        stability_threshold = max(self.confidence_threshold * 0.40, 0.25)  # –ü–æ–≤—ã—à–µ–Ω–æ —Å 0.1% –¥–æ 25-40%
                    elif is_volatile_symbol:
                        stability_threshold = max(self.confidence_threshold * 0.70, 0.35)  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                    else:
                        stability_threshold = max(self.confidence_threshold * 0.85, 0.45)
                    if confidence < stability_threshold:
                        return Signal(row.name, Action.HOLD, f"ml_—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å_—Ç—Ä–µ–±—É–µ—Ç_{int(stability_threshold*100)}%", current_price)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º (—Å–º—è–≥—á–µ–Ω–æ: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –æ–±—ä–µ–º –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω)
                # –î–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–µ–Ω–∞
                if not is_volatile_symbol and not self.is_ensemble:
                    volume_threshold_mult = 1.2
                    if not volume_ok and confidence < dynamic_threshold * volume_threshold_mult:
                        return Signal(row.name, Action.HOLD, f"ml_–æ–±—ä–µ–º_–Ω–µ_–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç_{strength}_{confidence_pct}%", current_price)
                # –°–∏–≥–Ω–∞–ª SHORT
                reason = f"ml_SHORT_—Å–∏–ª–∞_{strength}_{confidence_pct}%_TP_{tp_pct:.2f}%_SL_{sl_pct:.2f}%"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤
                signal_action = Action.SHORT
                self.signal_history.append((row.name, signal_action, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –¥–µ–Ω—å
                self.daily_signals_count[date_str] = signals_today + 1
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                from datetime import timedelta
                cutoff_date = (current_date - timedelta(days=7)).isoformat()
                self.daily_signals_count = {k: v for k, v in self.daily_signals_count.items() if k >= cutoff_date}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –¥–ª—è ML
                indicators_info = {
                    "strategy": "ML",
                    "prediction": "SHORT",
                    "confidence": round(confidence, 4),
                    "confidence_pct": confidence_pct,
                    "strength": strength,
                    "tp_pct": round(tp_pct, 2),
                    "sl_pct": round(sl_pct, 2),
                    "target_profit_margin_pct": profit_pct,
                    "leverage": leverage,
                    "volume": round(volume, 0) if np.isfinite(volume) else None,
                    "vol_sma": round(vol_sma, 0) if np.isfinite(vol_sma) else None,
                    "vol_ratio": round(volume / vol_sma, 2) if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else None,
                    "volume_ok": volume_ok,
                    "has_position": has_position.value if has_position else None,
                    "indicators": f"ML Confidence={confidence_pct}% ({strength}), Vol={volume:.0f}/{vol_sma:.0f} ({volume/vol_sma:.2f}x)" if np.isfinite(volume) and np.isfinite(vol_sma) and vol_sma > 0 else f"ML Confidence={confidence_pct}% ({strength})"
                }
                return Signal(row.name, Action.SHORT, reason, current_price, indicators_info=indicators_info)
            
            else:  # prediction == 0 (HOLD)
                # –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ (HOLD —Ç–æ–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è)
                self.signal_history.append((row.name, Action.HOLD, confidence))
                if len(self.signal_history) > self.max_signal_history:
                    self.signal_history.pop(0)
                
                reason = f"ml_–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ_—Å–∏–ª–∞_{strength}_{confidence_pct}%_–æ–∂–∏–¥–∞–Ω–∏–µ"
                return Signal(row.name, Action.HOLD, reason, current_price)
        
        except Exception as e:
            print(f"[ml_strategy] Error generating signal: {e}")
            return Signal(row.name, Action.HOLD, f"ml_–æ—à–∏–±–∫–∞_{str(e)[:20]}", current_price)


def build_ml_signals(
    df: pd.DataFrame,
    model_path: str,
    confidence_threshold: float = 0.5,
    min_signal_strength: str = "—Å–ª–∞–±–æ–µ",
    stability_filter: bool = True,
    leverage: int = 10,
    target_profit_pct_margin: float = 25.0,
    max_loss_pct_margin: float = 10.0,
    min_signals_per_day: int = 1,
    max_signals_per_day: int = 10,
) -> list[Signal]:
    """
    –°—Ç—Ä–æ–∏—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame.
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å OHLCV –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
        model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        min_signal_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ ("—Å–ª–∞–±–æ–µ", "—É–º–µ—Ä–µ–Ω–Ω–æ–µ", "—Å—Ä–µ–¥–Ω–µ–µ", "—Å–∏–ª—å–Ω–æ–µ", "–æ—á–µ–Ω—å_—Å–∏–ª—å–Ω–æ–µ")
        stability_filter: –§–∏–ª—å—Ç—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    
    Returns:
        –°–ø–∏—Å–æ–∫ Signal –æ–±—ä–µ–∫—Ç–æ–≤
    """
    strategy = MLStrategy(model_path, confidence_threshold, min_signal_strength, stability_filter, min_signals_per_day=min_signals_per_day, max_signals_per_day=max_signals_per_day)
    signals: list[Signal] = []
    position_bias: Optional[Bias] = None
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ DataFrame –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    df_work = df.copy()
    
    # –ï—Å–ª–∏ timestamp –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å
    if "timestamp" in df_work.columns:
        df_work = df_work.set_index("timestamp")
    elif not isinstance(df_work.index, pd.DatetimeIndex):
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å –≤ DatetimeIndex
        try:
            df_work.index = pd.to_datetime(df_work.index)
        except:
            pass
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ OHLCV
    required_cols = ["open", "high", "low", "close", "volume"]
    if not all(col in df_work.columns for col in required_cols):
        print(f"[ml_strategy] Warning: Missing required columns. Available: {df_work.columns.tolist()}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–∏–≥–Ω–∞–ª—ã
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), Action.HOLD, "ml_missing_data", 0.0) 
                for i in range(len(df_work))]
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏—á–∏ –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ–≥–æ DataFrame –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ä–∞
    # –≠—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É, —Ç–∞–∫ –∫–∞–∫ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ - —Å–∞–º–∞—è –∑–∞—Ç—Ä–∞—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π (–±–µ–∑ verbose –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ MTF-—Ä–µ–∂–∏–º –¥–ª—è ML (–ø–æ –æ–∫—Ä—É–∂–µ–Ω–∏—é, —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å train_* —Å–∫—Ä–∏–ø—Ç–∞–º–∏)
        import os
        # –í–ê–ñ–ù–û: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é MTF –≤—ã–∫–ª—é—á–µ–Ω (–∏–Ω–∞—á–µ 15m-–º–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–∞—é—Ç —á—É–∂–∏–µ —Ñ–∏—á–∏)
        ml_mtf_enabled_env = os.getenv("ML_MTF_ENABLED", "0")
        ml_mtf_enabled = ml_mtf_enabled_env not in ("0", "false", "False", "no")

        # –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ 15m
        df_with_features = strategy.feature_engineer.create_technical_indicators(df_work)

        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω MTF-—Ä–µ–∂–∏–º, –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∏—á–∏ 1h/4h –ø–æ —Ç–æ–π –∂–µ —Å—Ö–µ–º–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        if ml_mtf_enabled:
            try:
                # –°—Ç—Ä–æ–∏–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ OHLCV –¥–ª—è 1h –∏ 4h –∏–∑ 15m –¥–∞–Ω–Ω—ã—Ö
                ohlcv_agg = {
                    "open": "first",
                    "high": "max",
                    "low": "min",
                    "close": "last",
                    "volume": "sum",
                }
                df_1h = df_work.resample("60min").agg(ohlcv_agg).dropna()
                df_4h = df_work.resample("240min").agg(ohlcv_agg).dropna()

                higher_timeframes = {}
                if df_1h is not None and not df_1h.empty:
                    higher_timeframes["60"] = df_1h
                if df_4h is not None and not df_4h.empty:
                    higher_timeframes["240"] = df_4h

                if higher_timeframes:
                    df_with_features = strategy.feature_engineer.add_mtf_features(
                        df_with_features,
                        higher_timeframes,
                    )
                    print(f"[ml_strategy] MTF features enabled for ML signals (1h/4h). Columns: {len(df_with_features.columns)}")
                else:
                    print("[ml_strategy] MTF enabled but failed to build 1h/4h data ‚Äì using 15m-only features")
            except Exception as mtf_err:
                print(f"[ml_strategy] Warning: failed to add MTF features in build_ml_signals: {mtf_err}")
    except Exception as e:
        print(f"[ml_strategy] Error preparing features: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ
        return [Signal(df_work.index[i] if len(df_work) > 0 else pd.Timestamp.now(), Action.HOLD, f"ml_error_{str(e)[:20]}", 0.0) 
                for i in range(len(df_work))]
    
    for idx, row in df_with_features.iterrows():
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞ (—É–∂–µ —Å –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏)
            df_until_now = df_with_features.loc[:idx]
            
            # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 200 –±–∞—Ä–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (SMA200, –∏ —Ç.–¥.)
            if len(df_until_now) < 200:
                signals.append(Signal(idx, Action.HOLD, "ml_insufficient_data", row["close"]))
                continue
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ - –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∏—Ö
            signal = strategy.generate_signal(
                row=row,
                df=df_until_now,  # –£–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ñ–∏—á–∏
                has_position=position_bias,
                current_price=row["close"],
                leverage=leverage,
                target_profit_pct_margin=target_profit_pct_margin,
                max_loss_pct_margin=max_loss_pct_margin,
            )
            signals.append(signal)
            # –í–ê–ñ–ù–û: build_ml_signals –Ω–µ –¥–æ–ª–∂–µ–Ω —ç–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∑–∏—Ü–∏—é –ø–æ —Å–∏–≥–Ω–∞–ª–∞–º.
            # –†–µ–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –∏–∑–≤–µ—Å—Ç–Ω–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ live/backtest-–¥–≤–∏–∂–∫–∞ –∏ –¥–æ–ª–∂–Ω–∞ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –≤ generate_signal,
            # –∏–Ω–∞—á–µ stability_filter –Ω–∞—á–∏–Ω–∞–µ—Ç "–∑–∞–ª–∏–ø–∞—Ç—å" –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–æ–ª—å–∫–æ SHORT).
        except Exception as e:
            print(f"[ml_strategy] Error processing row {idx}: {e}")
            import traceback
            traceback.print_exc()
            signals.append(Signal(idx, Action.HOLD, f"ml_error_{str(e)[:20]}", row.get("close", 0.0)))
    
    return signals

